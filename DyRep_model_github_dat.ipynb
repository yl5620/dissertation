{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import torch.utils\n",
    "from datetime import timezone\n",
    "\n",
    "\n",
    "class EventsDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Base class for event datasets\n",
    "    '''\n",
    "    def __init__(self, TZ=None):\n",
    "        self.TZ = TZ  # timezone.utc\n",
    "\n",
    "        # Implement here these fields (see examples in actual datasets):\n",
    "        # self.FIRST_DATE = datetime()\n",
    "        # self.TEST_TIMESLOTS = []\n",
    "        # self.N_nodes = 100\n",
    "        # self.A_initial = np.random.randint(0, 2, size=(self.N_nodes, self.N_nodes))\n",
    "        # self.A_last = np.random.randint(0, 2, size=(self.N_nodes, self.N_nodes))\n",
    "        #\n",
    "        # self.all_events = []\n",
    "        # self.n_events = len(self.all_events)\n",
    "        #\n",
    "        # self.event_types = ['communication event']\n",
    "        # self.event_types_num = {'association event': 0}\n",
    "        # k = 1  # k >= 1 for communication events\n",
    "        # for t in self.event_types:\n",
    "        #     self.event_types_num[t] = k\n",
    "        #     k += 1\n",
    "\n",
    "\n",
    "    def get_Adjacency(self, multirelations=False):\n",
    "        return None, None, None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_events\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        tpl = self.all_events[index]\n",
    "        u, v, rel, time_cur = tpl\n",
    "\n",
    "        # Compute time delta in seconds (t_p - \\bar{t}_p_j) that will be fed to W_t\n",
    "        time_delta_uv = np.zeros((2, 4))  # two nodes x 4 values\n",
    "\n",
    "        # most recent previous time for all nodes\n",
    "        time_bar = self.time_bar.copy()\n",
    "        assert u != v, (tpl, rel)\n",
    "\n",
    "        u = int(u)\n",
    "        v = int(v)\n",
    "        \n",
    "        for c, j in enumerate([u, v]):\n",
    "            t = datetime.datetime.fromtimestamp(self.time_bar[j][0], tz=self.TZ)\n",
    "            if t.toordinal() >= self.FIRST_DATE.toordinal():  # assume no events before FIRST_DATE\n",
    "                td = time_cur - t\n",
    "                time_delta_uv[c] = np.array([td.days,  # total number of days, still can be a big number\n",
    "                                             td.seconds // 3600,  # hours, max 24\n",
    "                                             (td.seconds // 60) % 60,  # minutes, max 60\n",
    "                                             td.seconds % 60],  # seconds, max 60\n",
    "                                            np.float64)\n",
    "                # assert time_delta_uv.min() >= 0, (index, tpl, time_delta_uv[c], node_global_time[j])\n",
    "            else:\n",
    "                raise ValueError('unexpected result', t, self.FIRST_DATE)\n",
    "            self.time_bar[j] = time_cur.timestamp()  # last time stamp for nodes u and v\n",
    "\n",
    "        k = self.event_types_num[rel]\n",
    "\n",
    "        # sanity checks\n",
    "        assert np.float64(time_cur.timestamp()) == time_cur.timestamp(), (\n",
    "        np.float64(time_cur.timestamp()), time_cur.timestamp())\n",
    "        time_cur = np.float64(time_cur.timestamp())\n",
    "        time_bar = time_bar.astype(np.float64)\n",
    "        time_cur = torch.from_numpy(np.array([time_cur])).double()\n",
    "        assert time_bar.max() <= time_cur, (time_bar.max(), time_cur)\n",
    "        return u, v, time_delta_uv, k, time_bar, time_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "from datetime import timezone\n",
    "import dateutil.parser\n",
    "\n",
    "\n",
    "def iso_parse(dt):\n",
    "    # return datetime.fromisoformat(dt)  # python >= 3.7\n",
    "    return dateutil.parser.isoparse(dt)\n",
    "\n",
    "class GithubDataset(EventsDataset):\n",
    "\n",
    "    def __init__(self, split, data_dir='./Github'):\n",
    "        super(GithubDataset, self).__init__()\n",
    "\n",
    "        if split == 'train':\n",
    "            time_start = 0\n",
    "            time_end = datetime.datetime(2013, 8, 31, tzinfo=self.TZ).toordinal()\n",
    "        elif split == 'test':\n",
    "            time_start = datetime.datetime(2013, 9, 1, tzinfo=self.TZ).toordinal()\n",
    "            time_end = datetime.datetime(2014, 1, 1, tzinfo=self.TZ).toordinal()\n",
    "        else:\n",
    "            raise ValueError('invalid split', split)\n",
    "\n",
    "        self.FIRST_DATE = datetime.datetime(2012, 12, 28, tzinfo=self.TZ)\n",
    "\n",
    "        self.TEST_TIMESLOTS = [datetime.datetime(2013, 9, 1, tzinfo=self.TZ),\n",
    "                               datetime.datetime(2013, 9, 25, tzinfo=self.TZ),\n",
    "                               datetime.datetime(2013, 10, 20, tzinfo=self.TZ),\n",
    "                               datetime.datetime(2013, 11, 15, tzinfo=self.TZ),\n",
    "                               datetime.datetime(2013, 12, 10, tzinfo=self.TZ),\n",
    "                               datetime.datetime(2014, 1, 1, tzinfo=self.TZ)]\n",
    "\n",
    "\n",
    "\n",
    "        with open(os.path.join(data_dir, 'github_284users_events_2013.pkl'), 'rb') as f:\n",
    "            users_events, event_types = pickle.load(f)\n",
    "\n",
    "        with open(os.path.join(data_dir, 'github_284users_follow_2011_2012.pkl'), 'rb') as f:\n",
    "            users_follow = pickle.load(f)\n",
    "\n",
    "        print(event_types)\n",
    "\n",
    "        self.events2name = {}\n",
    "        for e in event_types:\n",
    "            self.events2name[event_types[e]] = e\n",
    "        print(self.events2name)\n",
    "\n",
    "        self.event_types = ['ForkEvent', 'PushEvent', 'WatchEvent', 'IssuesEvent', 'IssueCommentEvent',\n",
    "                           'PullRequestEvent', 'CommitCommentEvent']\n",
    "        self.assoc_types = ['FollowEvent']\n",
    "        self.is_comm = lambda d: self.events2name[d['type']] in self.event_types\n",
    "        self.is_assoc = lambda d: self.events2name[d['type']] in self.assoc_types\n",
    "\n",
    "        user_ids = {}\n",
    "        for id, user in enumerate(sorted(users_events)):\n",
    "            user_ids[user] = id\n",
    "\n",
    "        self.N_nodes = len(user_ids)\n",
    "\n",
    "        self.A_initial = np.zeros((self.N_nodes, self.N_nodes))\n",
    "        for user in users_follow:\n",
    "            for e in users_follow[user]:\n",
    "                assert e['type'] in self.assoc_types, e['type']\n",
    "                if e['login'] in users_events:\n",
    "                    self.A_initial[user_ids[user], user_ids[e['login']]] = 1\n",
    "\n",
    "        self.A_last = np.zeros((self.N_nodes, self.N_nodes))\n",
    "        for user in users_events:\n",
    "            for e in users_events[user]:\n",
    "                if self.events2name[e['type']] in self.assoc_types:\n",
    "                    self.A_last[user_ids[user], user_ids[e['login']]] = 1\n",
    "        self.time_bar = np.full(self.N_nodes, self.FIRST_DATE.timestamp())\n",
    "\n",
    "\n",
    "        print('\\nA_initial', np.sum(self.A_initial))\n",
    "        print('A_last', np.sum(self.A_last), '\\n')\n",
    "\n",
    "        all_events = []\n",
    "        for user in users_events:\n",
    "            if user not in user_ids:\n",
    "                continue\n",
    "            user_id = user_ids[user]\n",
    "            for ind, event in enumerate(users_events[user]):\n",
    "                event['created_at'] = datetime.datetime.fromtimestamp(event['created_at'])\n",
    "                if event['created_at'].toordinal() >= time_start and event['created_at'].toordinal() <= time_end:\n",
    "                    if 'owner' in event:\n",
    "                        if event['owner'] not in user_ids:\n",
    "                            continue\n",
    "                        user_id2 = user_ids[event['owner']]\n",
    "                    elif 'login' in event:\n",
    "                        if event['login'] not in user_ids:\n",
    "                            continue\n",
    "                        user_id2 = user_ids[event['login']]\n",
    "                    else:\n",
    "                        raise ValueError('invalid event', event)\n",
    "                    if user_id != user_id2:\n",
    "                        all_events.append((user_id, user_id2,\n",
    "                                           self.events2name[event['type']], event['created_at']))\n",
    "\n",
    "        self.all_events = sorted(all_events, key=lambda t: t[3].timestamp())\n",
    "        print('\\n%s' % split.upper())\n",
    "        print('%d events between %d users loaded' % (len(self.all_events), self.N_nodes))\n",
    "        print('%d communication events' % (len([t for t in self.all_events if t[2] == 1])))\n",
    "        print('%d assocition events' % (len([t for t in self.all_events if t[2] == 0])))\n",
    "\n",
    "        self.event_types_num = {self.assoc_types[0]: 0}\n",
    "        k = 1  # k >= 1 for communication events\n",
    "        for t in self.event_types:\n",
    "            self.event_types_num[t] = k\n",
    "            k += 1\n",
    "\n",
    "        self.n_events = len(self.all_events)\n",
    "\n",
    "\n",
    "    def get_Adjacency(self, multirelations=False):\n",
    "        if multirelations:\n",
    "            print('warning: Github has only one relation type (FollowEvent), so multirelations are ignored')\n",
    "        return self.A_initial, self.assoc_types, self.A_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PushEvent': 0, 'WatchEvent': 1, 'ForkEvent': 2, 'IssuesEvent': 3, 'FollowEvent': 4, 'PullRequestEvent': 5, 'IssueCommentEvent': 6, 'CommitCommentEvent': 7}\n",
      "{0: 'PushEvent', 1: 'WatchEvent', 2: 'ForkEvent', 3: 'IssuesEvent', 4: 'FollowEvent', 5: 'PullRequestEvent', 6: 'IssueCommentEvent', 7: 'CommitCommentEvent'}\n",
      "\n",
      "A_initial 298.0\n",
      "A_last 1420.0 \n",
      "\n",
      "\n",
      "TRAIN\n",
      "11627 events between 284 users loaded\n",
      "0 communication events\n",
      "0 assocition events\n",
      "{'PushEvent': 0, 'WatchEvent': 1, 'ForkEvent': 2, 'IssuesEvent': 3, 'FollowEvent': 4, 'PullRequestEvent': 5, 'IssueCommentEvent': 6, 'CommitCommentEvent': 7}\n",
      "{0: 'PushEvent', 1: 'WatchEvent', 2: 'ForkEvent', 3: 'IssuesEvent', 4: 'FollowEvent', 5: 'PullRequestEvent', 6: 'IssueCommentEvent', 7: 'CommitCommentEvent'}\n",
      "\n",
      "A_initial 298.0\n",
      "A_last 1420.0 \n",
      "\n",
      "\n",
      "TEST\n",
      "9099 events between 284 users loaded\n",
      "0 communication events\n",
      "0 assocition events\n",
      "Train set preview (first 5 events):\n",
      "(74, 6, 'PushEvent', datetime.datetime(2013, 1, 1, 8, 53, 4))\n",
      "(103, 268, 'IssueCommentEvent', datetime.datetime(2013, 1, 1, 14, 42, 13))\n",
      "(103, 268, 'IssueCommentEvent', datetime.datetime(2013, 1, 1, 14, 43, 27))\n",
      "(103, 268, 'IssueCommentEvent', datetime.datetime(2013, 1, 1, 14, 45, 54))\n",
      "(103, 268, 'IssueCommentEvent', datetime.datetime(2013, 1, 1, 14, 47, 34))\n",
      "\n",
      "Test set preview (first 5 events):\n",
      "(147, 175, 'WatchEvent', datetime.datetime(2013, 9, 1, 0, 1, 15))\n",
      "(178, 176, 'IssueCommentEvent', datetime.datetime(2013, 9, 1, 0, 2, 44))\n",
      "(6, 74, 'PushEvent', datetime.datetime(2013, 9, 1, 0, 34, 40))\n",
      "(6, 74, 'PushEvent', datetime.datetime(2013, 9, 1, 0, 37, 42))\n",
      "(6, 74, 'PushEvent', datetime.datetime(2013, 9, 1, 0, 48, 28))\n"
     ]
    }
   ],
   "source": [
    "datdir = '/Users/amberrrrrr/Desktop/huozhe/Github'\n",
    "train_set = GithubDataset('train', data_dir=datdir)\n",
    "test_set = GithubDataset('test', data_dir=datdir)\n",
    "\n",
    "# Preview the first few lines of the train set and test set\n",
    "print(\"Train set preview (first 5 events):\")\n",
    "for event in train_set.all_events[:5]:\n",
    "    print(event)\n",
    "\n",
    "print(\"\\nTest set preview (first 5 events):\")\n",
    "for event in test_set.all_events[:5]:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_embeddings = np.random.randn(train_set.N_nodes, 32)\n",
    "A_initial = train_set.get_Adjacency()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DyRep(nn.Module):\n",
    "    def __init__(self,\n",
    "                 node_embeddings,\n",
    "                 A_initial=None,\n",
    "                 N_surv_samples=5,\n",
    "                 n_hidden=32,\n",
    "                 sparse=False,\n",
    "                 node_degree_global=None,\n",
    "                 rnd=np.random.RandomState(111)):\n",
    "        super(DyRep, self).__init__()\n",
    "    \n",
    "        # initialisations\n",
    "        self.opt = True\n",
    "        self.exp = True\n",
    "        self.rnd = rnd\n",
    "        self.n_hidden = n_hidden\n",
    "        self.sparse = sparse\n",
    "        self.N_surv_samples = N_surv_samples\n",
    "        self.node_degree_global = node_degree_global\n",
    "        self.N_nodes = A_initial.shape[0]\n",
    "        if A_initial is not None and len(A_initial.shape) == 2:\n",
    "            A_initial = A_initial[:, :, None]\n",
    "        self.n_assoc_types = 1\n",
    "\n",
    "        self.initialize(node_embeddings, A_initial)\n",
    "        self.W_h = nn.Linear(in_features=n_hidden, out_features=n_hidden)\n",
    "        self.W_struct = nn.Linear(n_hidden * self.n_assoc_types, n_hidden)\n",
    "        self.W_rec = nn.Linear(n_hidden, n_hidden)\n",
    "        self.W_t = nn.Linear(4, n_hidden)\n",
    "\n",
    "        n_types = 2  # associative and communicative\n",
    "        d1 = self.n_hidden + (0)\n",
    "        d2 = self.n_hidden + (0)\n",
    "\n",
    "        d1 += self.n_hidden\n",
    "        d2 += self.n_hidden\n",
    "        self.omega = nn.ModuleList([nn.Linear(d1, 1), nn.Linear(d2, 1)])\n",
    "\n",
    "        self.psi = nn.Parameter(0.5 * torch.ones(n_types)) \n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # print('before Xavier', m.weight.data.shape, m.weight.data.min(), m.weight.data.max())\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "\n",
    "    def generate_S_from_A(self):\n",
    "        if isinstance(self.A, np.ndarray):\n",
    "            self.A = torch.tensor(self.A, dtype=torch.float32)  # Convert A to a tensor if it's a numpy array\n",
    "        S = self.A.new_empty(self.N_nodes, self.N_nodes, self.n_assoc_types).fill_(0)\n",
    "        for rel in range(self.n_assoc_types):\n",
    "            D = torch.sum(self.A[:, :, rel], dim=1).float()\n",
    "            for i, v in enumerate(torch.nonzero(D, as_tuple=False).squeeze()):\n",
    "                u = torch.nonzero(self.A[v, :, rel].squeeze(), as_tuple=False).squeeze()\n",
    "                S[v, u, rel] = 1. / D[v]\n",
    "        self.S = S\n",
    "        # Check that values in each row of S add up to 1\n",
    "        for rel in range(self.n_assoc_types):\n",
    "            S = self.S[:, :, rel]\n",
    "            assert torch.sum(S[self.A[:, :, rel] == 0]) < 1e-5, torch.sum(S[self.A[:, :, rel] == 0])\n",
    "\n",
    "    def initialize(self,node_embeddings, A_initial,keepS=False):\n",
    "        print('initialize model''s node embeddings and adjacency matrices for %d nodes' % self.N_nodes)\n",
    "        # Initial embeddings\n",
    "        if node_embeddings is not None:\n",
    "            z = np.pad(node_embeddings, ((0, 0), (0, self.n_hidden - node_embeddings.shape[1])), 'constant')\n",
    "            z = torch.from_numpy(z).float()\n",
    "\n",
    "        if A_initial is None:\n",
    "            print('initial random prediction of A')\n",
    "            A = torch.zeros(self.N_nodes, self.N_nodes, self.n_assoc_types + int(self.sparse))\n",
    "\n",
    "            for i in range(self.N_nodes):\n",
    "                for j in range(i + 1, self.N_nodes):\n",
    "                    if self.sparse:\n",
    "                        if self.n_assoc_types == 1:\n",
    "                            pvals = [0.95, 0.05]\n",
    "                        elif self.n_assoc_types == 2:\n",
    "                            pvals = [0.9, 0.05, 0.05]\n",
    "                        elif self.n_assoc_types == 3:\n",
    "                            pvals = [0.91, 0.03, 0.03, 0.03]\n",
    "                        elif self.n_assoc_types == 4:\n",
    "                            pvals = [0.9, 0.025, 0.025, 0.025, 0.025]\n",
    "                        else:\n",
    "                            raise NotImplementedError(self.n_assoc_types)\n",
    "                        ind = np.nonzero(np.random.multinomial(1, pvals))[0][0]\n",
    "                    else:\n",
    "                        ind = np.random.randint(0, self.n_assoc_types, size=1)\n",
    "                    A[i, j, ind] = 1\n",
    "                    A[j, i, ind] = 1\n",
    "            assert torch.sum(torch.isnan(A)) == 0, (torch.sum(torch.isnan(A)), A)\n",
    "            if self.sparse:\n",
    "                A = A[:, :, 1:]\n",
    "\n",
    "        else:\n",
    "            print('A_initial', A_initial.shape)\n",
    "            A = torch.from_numpy(A_initial).float()\n",
    "            if len(A.shape) == 2:\n",
    "                A = A.unsqueeze(2)\n",
    "\n",
    "        # make these variables part of the model\n",
    "        self.register_buffer('z', z)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        self.A = A  \n",
    "        if not keepS:\n",
    "            self.generate_S_from_A()\n",
    "\n",
    "        self.Lambda_dict = torch.zeros(5000)\n",
    "        self.time_keys = []\n",
    "\n",
    "        self.t_p = 0  # global counter of iterations\n",
    "    \n",
    "    def check_S(self):\n",
    "        for rel in range(self.n_assoc_types):\n",
    "            rows = torch.nonzero(torch.sum(self.A[:, :, rel], dim=1).float())\n",
    "            # check that the sum in all rows equal 1\n",
    "            assert torch.all(torch.abs(torch.sum(self.S[:, :, rel], dim=1)[rows] - 1) < 1e-1), torch.abs(torch.sum(self.S[:, :, rel], dim=1)[rows] - 1)\n",
    "\n",
    "    \n",
    "    def g_fn(self,z_cat, k, edge_type=None, z2=None):\n",
    "        if z2 is not None:\n",
    "            z_cat = torch.cat((z_cat, z2), dim=1)\n",
    "        else:\n",
    "            raise NotImplementedError('')\n",
    "        g = z_cat.new(len(z_cat), 1).fill_(0)\n",
    "        idx = k <= 0\n",
    "        if torch.sum(idx) > 0:\n",
    "            if edge_type is not None:\n",
    "                z_cat1 = torch.cat((z_cat[idx], edge_type[idx, :self.n_assoc_types]), dim=1)\n",
    "            else:\n",
    "                z_cat1 = z_cat[idx]\n",
    "            g[idx] = self.omega[0](z_cat1)\n",
    "        idx = k > 0\n",
    "        if torch.sum(idx) > 0:\n",
    "            if edge_type is not None:\n",
    "                z_cat1 = torch.cat((z_cat[idx], edge_type[idx, self.n_assoc_types:]), dim=1)\n",
    "            else:\n",
    "                z_cat1 = z_cat[idx]\n",
    "            g[idx] = self.omega[1](z_cat1)\n",
    "\n",
    "        g = g.flatten()\n",
    "        return g\n",
    "    \n",
    "    def intensity_rate_lambda(self,z_u, z_v, k):\n",
    "        z_u = z_u.view(-1, self.n_hidden).contiguous()\n",
    "        z_v = z_v.view(-1, self.n_hidden).contiguous()\n",
    "        edge_type = None\n",
    "        g = 0.5 * (self.g_fn(z_u, (k > 0).long(), edge_type=edge_type, z2=z_v) + self.g_fn(z_v, (k > 0).long(),edge_type=edge_type, z2=z_u))  # make it symmetric, because most events are symmetric\n",
    "        psi = self.psi[(k > 0).long()]\n",
    "        g_psi = torch.clamp(g / (psi + 1e-7), -75, 75)  # to prevent overflow\n",
    "        Lambda = psi * (torch.log(1 + torch.exp(-g_psi)) + g_psi)\n",
    "        return Lambda\n",
    "    \n",
    "    def update_node_embed(self,prev_embed, node1, node2, time_delta_uv):\n",
    "        # z contains all node embeddings of previous time \\bar{t}\n",
    "        # S also corresponds to previous time stamp, because it's not updated yet based on this event\n",
    "\n",
    "        node_embed = prev_embed\n",
    "\n",
    "        node_degree = {} # we need degrees to update S\n",
    "        z_new = prev_embed.clone()  # to allow in place changes while keeping gradients\n",
    "        h_u_struct = prev_embed.new_zeros((2, self.n_hidden, self.n_assoc_types))\n",
    "        for c, (v, u, delta_t) in enumerate(zip([node1, node2], [node2, node1], time_delta_uv)):  # i is the other node involved in the event\n",
    "            node_degree[u] = np.zeros(self.n_assoc_types)\n",
    "            for rel in range(self.n_assoc_types):\n",
    "                Neighb_u = self.A[u, :, rel] > 0  # when update embedding for node v, we need neighbors of u and vice versa!\n",
    "                N_neighb = torch.sum(Neighb_u).item()  # number of neighbors for node u\n",
    "                node_degree[u][rel] = N_neighb\n",
    "                if N_neighb > 0:  # node has no neighbors\n",
    "                    h_prev_i = self.W_h(node_embed[Neighb_u]).view(N_neighb, self.n_hidden)\n",
    "                    # attention over neighbors\n",
    "                    q_ui = torch.exp(self.S[u, Neighb_u, rel]).view(N_neighb, 1)\n",
    "                    q_ui = q_ui / (torch.sum(q_ui) + 1e-7)\n",
    "                    h_u_struct[c, :, rel] = torch.max(torch.sigmoid(q_ui * h_prev_i), dim=0)[0].view(1, self.n_hidden)\n",
    "\n",
    "        h1 = self.W_struct(h_u_struct.view(2, self.n_hidden * self.n_assoc_types))\n",
    "\n",
    "        h2 = self.W_rec(node_embed[[node1, node2], :].view(2, -1))\n",
    "        h3 = self.W_t(time_delta_uv.float()).view(2, self.n_hidden)\n",
    "\n",
    "        z_new[[node1, node2], :] = torch.sigmoid(h1 + h2 + h3)\n",
    "        return node_degree, z_new\n",
    "    \n",
    "    def update_S_A(self, u, v, k, node_degree, lambda_uv_t):\n",
    "        if k <= 0 :  # Association event\n",
    "            # do not update in case of latent graph\n",
    "            self.A[u, v, np.abs(k)] = self.A[v, u, np.abs(k)] = 1  # 0 for CloseFriends, k = -1 for the second relation, so it's abs(k) matrix in self.A\n",
    "        A = self.A\n",
    "        indices = torch.arange(self.N_nodes)\n",
    "        for rel in range(self.n_assoc_types):\n",
    "            if k > 0 and A[u, v, rel] == 0:  # Communication event, no Association exists\n",
    "                continue  # do not update S and A\n",
    "            else:\n",
    "                for j, i in zip([u, v], [v, u]):\n",
    "                    # i is the \"other node involved in the event\"\n",
    "                    try:\n",
    "                        degree = node_degree[j]\n",
    "                    except:\n",
    "                        print(list(node_degree.keys()))\n",
    "                        raise\n",
    "                    y = self.S[j, :, rel]\n",
    "                    # assert torch.sum(torch.isnan(y)) == 0, ('b', j, degree[rel], node_degree_global[rel][j.item()], y)\n",
    "                    b = 0 if degree[rel] == 0 else 1. / (float(degree[rel]) + 1e-7)\n",
    "                    if k > 0 and A[u, v, rel] > 0:  # Communication event, Association exists\n",
    "                        y[i] = b + lambda_uv_t\n",
    "                    elif k <= 0 and A[u, v, rel] > 0:  # Association event\n",
    "                        if self.node_degree_global[rel][j] == 0:\n",
    "                            b_prime = 0\n",
    "                        else:\n",
    "                            b_prime = 1. / (float(self.node_degree_global[rel][j]) + 1e-7)\n",
    "                        x = b_prime - b\n",
    "                        y[i] = b + lambda_uv_t\n",
    "                        w = (y != 0) & (indices != int(i))\n",
    "                        y[w] = y[w] - x\n",
    "                    y /= (torch.sum(y) + 1e-7)  # normalize\n",
    "                    self.S[j, :, rel] = y\n",
    "        return \n",
    "    \n",
    "    # conditional density calculation to predict the next event (the probability of the next event for each pair of nodes)\n",
    "    def cond_density(self,time_bar,u, v):\n",
    "        N = self.N_nodes\n",
    "        if not self.time_keys:  # Checks if time_keys is empty\n",
    "            print(\"Warning: time_keys is empty. No operations performed.\")\n",
    "            return torch.zeros((2, self.N_nodes)) \n",
    "        s = self.Lambda_dict.new_zeros((2, N))\n",
    "        #normalize lambda values by dividing by the number of events\n",
    "        Lambda_sum = torch.cumsum(self.Lambda_dict.flip(0), 0).flip(0)  / len(self.Lambda_dict)\n",
    "        time_keys_min = self.time_keys[0]\n",
    "        time_keys_max = self.time_keys[-1]\n",
    "\n",
    "        indices = []\n",
    "        l_indices = []\n",
    "        t_bar_min = torch.min(time_bar[[u, v]]).item()\n",
    "        if t_bar_min < time_keys_min:\n",
    "            start_ind_min = 0\n",
    "        elif t_bar_min > time_keys_max:\n",
    "            # it means t_bar will always be larger, so there is no history for these nodes\n",
    "            return s\n",
    "        else:\n",
    "            start_ind_min = self.time_keys.index(int(t_bar_min))\n",
    "\n",
    "        # print(\"time_bar shape:\", time_bar.shape)\n",
    "        # print(\"Expanded and reshaped time_bar shape:\", time_bar[[u, v]].view(1, 2).expand(N, -1).t().contiguous().view(2 * N, 1).shape)\n",
    "        # print(\"Repeated time_bar shape:\", time_bar.repeat(2, 1).shape)\n",
    "        # Reshape expanded and reshaped time_bar\n",
    "        expanded_time_bar = time_bar[[u, v]].view(1, 2).expand(N, -1).t().contiguous().view(2 * N, 1)\n",
    "        # Adjust repeated time_bar to match the expanded shape\n",
    "        adjusted_repeated_time_bar = time_bar.repeat(2, 1).view(2 * N, 1)\n",
    "        # Now concatenate along dimension 1 (should work as both tensors are (168, 1))\n",
    "        max_pairs = torch.max(torch.cat((expanded_time_bar, adjusted_repeated_time_bar), dim=1), dim=1)[0].view(2, N).long()\n",
    "        # max_pairs = torch.max(torch.cat((time_bar[[u, v]].view(1, 2).expand(N, -1).t().contiguous().view(2 * N, 1),\n",
    "        #                                     time_bar.repeat(2, 1)), dim=1), dim=1)[0].view(2, N).long().data.cpu().numpy()  # 2,N\n",
    "\n",
    "        # compute cond density for all pairs of u and some i, then of v and some i\n",
    "        c1, c2 = 0, 0\n",
    "        for c, j in enumerate([u, v]):  # range(i + 1, N):\n",
    "            for i in range(N):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                # most recent timestamp of either u or v\n",
    "                t_bar = max_pairs[c, i]\n",
    "                c2 += 1\n",
    "\n",
    "                if t_bar < time_keys_min:\n",
    "                    start_ind = 0  # it means t_bar is beyond the history we kept, so use maximum period saved\n",
    "                elif t_bar > time_keys_max:\n",
    "                    continue  # it means t_bar is current event, so there is no history for this pair of nodes\n",
    "                else:\n",
    "                    # t_bar is somewhere in between time_keys_min and time_keys_min\n",
    "                    start_ind = self.time_keys.index(t_bar, start_ind_min)\n",
    "\n",
    "                indices.append((c, i))\n",
    "                l_indices.append(start_ind)\n",
    "\n",
    "        indices = np.array(indices)\n",
    "        l_indices = np.array(l_indices)\n",
    "        s[indices[:, 0], indices[:, 1]] = Lambda_sum[l_indices]\n",
    "\n",
    "        return s\n",
    "    \n",
    "    # forward pass\n",
    "    def forward(self,data):\n",
    "        # opt is batch_update\n",
    "        data[2] = data[2].float()\n",
    "        data[4] = data[4].double()\n",
    "        data[5] = data[5].double()\n",
    "        u, v, k = data[0], data[1], data[3]\n",
    "        time_delta_uv = data[2]\n",
    "        time_bar = data[4]\n",
    "        time_cur = data[5]\n",
    "        event_types = k\n",
    "        # u, v, time_delta_uv, event_types, time_bar, time_cur = data\n",
    "        B = len(u)\n",
    "        assert len(event_types) == B, (len(event_types), B)\n",
    "        N = self.N_nodes\n",
    "\n",
    "        A_pred, Surv = None, None\n",
    "        A_pred = self.A.new_zeros(B, N, N).fill_(0)\n",
    "        Surv = self.A.new_zeros(B, N, N).fill_(0)\n",
    "\n",
    "        if self.opt:\n",
    "            embeddings1, embeddings2, node_degrees = [], [], []\n",
    "            embeddings_non1, embeddings_non2 = [], []\n",
    "        else:\n",
    "            lambda_uv_t, lambda_uv_t_non_events = [], []\n",
    "\n",
    "        assert torch.min(time_delta_uv) >= 0, ('events must be in chronological order', torch.min(time_delta_uv))\n",
    "\n",
    "        time_mn = torch.from_numpy(np.array([0, 0, 0, 0])).float().view(1, 1, 4)\n",
    "        time_sd = torch.from_numpy(np.array([50, 7, 15, 15])).float().view(1, 1, 4)\n",
    "        time_delta_uv = (time_delta_uv - time_mn) / time_sd\n",
    "\n",
    "        reg = []\n",
    "\n",
    "        S_batch = []\n",
    "\n",
    "        z_all = []\n",
    "\n",
    "        u_all = u.data.cpu().numpy()\n",
    "        v_all = v.data.cpu().numpy()\n",
    "\n",
    "\n",
    "        for it, k in enumerate(event_types):\n",
    "            # k = 0: association event (rare)\n",
    "            # k = 1,2,3: communication event (frequent)\n",
    "\n",
    "            u_it, v_it = u_all[it], v_all[it]\n",
    "            z_prev = self.z if it == 0 else z_all[it - 1]\n",
    "\n",
    "            # 1. Compute intensity rate lambda based on node embeddings at previous time step (Eq. 1)\n",
    "            if self.opt:\n",
    "                # store node embeddings, compute lambda and S,A later based on the entire batch\n",
    "                embeddings1.append(z_prev[u_it])\n",
    "                embeddings2.append(z_prev[v_it])\n",
    "            else:\n",
    "                # accumulate intensity rate of events for this batch based on new embeddings\n",
    "                lambda_uv_t.append(self.intensity_rate_lambda(z_prev[u_it], z_prev[v_it], torch.zeros(1).long() + k))\n",
    "                # intensity_rate_lambda(z_u, z_v, k,n_hidden,psi,n_assoc_types,omega,edge_type=None)\n",
    "\n",
    "\n",
    "            # 2. Update node embeddings\n",
    "            node_degree, z_new = self.update_node_embed(z_prev, u_it, v_it, time_delta_uv[it])  # / 3600.)  # hours\n",
    "            # update_node_embed(prev_embed, node1, node2, time_delta_uv, n_hidden,n_assoc_types, S, A, W_h, W_struct, W_rec, W_t)\n",
    "            if self.opt:\n",
    "                node_degrees.append(node_degree)\n",
    "\n",
    "\n",
    "            # 3. Update S and A\n",
    "            if not self.opt:\n",
    "                # we can update S and A based on current pair of nodes even during test time,\n",
    "                # because S, A are not used in further steps for this iteration\n",
    "                self.update_S_A(u_it, v_it, k.item(), node_degree, lambda_uv_t[it])  #\n",
    "                # update_S_A(A,S, u,v, k, node_degree, lambda_uv_t, N_nodes,n_assoc_types,node_degree_global)\n",
    "\n",
    "            # update most recent degrees of nodes used to update S\n",
    "            assert self.node_degree_global is not None\n",
    "            for j in [u_it, v_it]:\n",
    "                for rel in range(self.n_assoc_types):\n",
    "                    self.node_degree_global[rel][j] = node_degree[j][rel]\n",
    "\n",
    "\n",
    "            # Non events loss\n",
    "            # this is not important for test time, but we still compute these losses for debugging purposes\n",
    "            # get random nodes except for u_it, v_it\n",
    "            # 4. compute lambda for sampled events that do not happen -> to compute survival probability in loss\n",
    "            uv_others = self.rnd.choice(np.delete(np.arange(N), [u_it, v_it]), size= self.N_surv_samples * 2, replace=False)\n",
    "                # assert len(np.unique(uv_others)) == len(uv_others), ('nodes must be unique', uv_others)\n",
    "            for q in range(self.N_surv_samples):\n",
    "                assert u_it != uv_others[q], (u_it, uv_others[q])\n",
    "                assert v_it != uv_others[self.N_surv_samples + q], (v_it, uv_others[self.N_surv_samples + q])\n",
    "                if self.opt:\n",
    "                    embeddings_non1.extend([z_prev[u_it], z_prev[uv_others[self.N_surv_samples + q]]])\n",
    "                    embeddings_non2.extend([z_prev[uv_others[q]], z_prev[v_it]])\n",
    "                else:\n",
    "                    for k_ in range(2):\n",
    "                        lambda_uv_t_non_events.append(\n",
    "                            self.intensity_rate_lambda(z_prev[u_it],\n",
    "                                                        z_prev[uv_others[q]], torch.zeros(1).long() + k_))\n",
    "                        lambda_uv_t_non_events.append(\n",
    "                            self.intensity_rate_lambda(z_prev[uv_others[self.N_surv_samples + q]],\n",
    "                                                        z_prev[v_it],\n",
    "                                                        torch.zeros(1).long() + k_))\n",
    "\n",
    "\n",
    "            # 5. compute conditional density for all possible pairs\n",
    "            # here it's important NOT to use any information that the event between nodes u,v has happened\n",
    "            # so, we use node embeddings of the previous time step: z_prev\n",
    "            with torch.no_grad():\n",
    "                z_cat = torch.cat((z_prev[u_it].detach().unsqueeze(0).expand(N, -1),\n",
    "                                    z_prev[v_it].detach().unsqueeze(0).expand(N, -1)), dim=0)\n",
    "                Lambda = self.intensity_rate_lambda(z_cat, z_prev.detach().repeat(2, 1),\n",
    "                                                    torch.zeros(len(z_cat)).long() + k).detach()\n",
    "                \n",
    "                A_pred[it, u_it, :] = Lambda[:N]\n",
    "                A_pred[it, v_it, :] = Lambda[N:]\n",
    "\n",
    "                assert torch.sum(torch.isnan(A_pred[it])) == 0, (it, torch.sum(torch.isnan(A_pred[it])))\n",
    "                # Compute the survival term (See page 3 in the paper)\n",
    "                # we only need to compute the term for rows u_it and v_it in our matrix s to save time\n",
    "                # because we will compute rank only for nodes u_it and v_it\n",
    "                s1 = self.cond_density(time_bar[it], u_it, v_it)\n",
    "                # cond_density(time_bar, u, v, N_nodes, Lambda_dict, time_keys)\n",
    "                Surv[it, [u_it, v_it], :] = s1\n",
    "\n",
    "                time_key = int(time_cur[it].item())\n",
    "                idx = np.delete(np.arange(N), [u_it, v_it])  # nonevents for node u\n",
    "                idx = np.concatenate((idx, idx + N))   # concat with nonevents for node v\n",
    "\n",
    "                if len(self.time_keys) >= len(self.Lambda_dict):\n",
    "                    # shift in time (remove the oldest record)\n",
    "                    time_keys = np.array(self.time_keys)\n",
    "                    time_keys[:-1] = time_keys[1:]\n",
    "                    self.time_keys = list(time_keys[:-1])  # remove last\n",
    "                    self.Lambda_dict[:-1] = self.Lambda_dict.clone()[1:]\n",
    "                    self.Lambda_dict[-1] = 0\n",
    "\n",
    "                self.Lambda_dict[len(self.time_keys)] = Lambda[idx].sum().detach()  # total intensity of non events for the current time step\n",
    "                self.time_keys.append(time_key)\n",
    "\n",
    "            # Once we made predictions for the training and test sample, we can update node embeddings\n",
    "            z_all.append(z_new)\n",
    "            # update S\n",
    "\n",
    "            self.A = self.S\n",
    "            S_batch.append(self.S.data.cpu().numpy())\n",
    "\n",
    "            self.t_p += 1\n",
    "\n",
    "        self.z = z_new  # update node embeddings\n",
    "\n",
    "        # Batch update\n",
    "        if self.opt:\n",
    "            lambda_uv_t = self.intensity_rate_lambda(torch.stack(embeddings1, dim=0),\n",
    "                                                        torch.stack(embeddings2, dim=0), event_types)\n",
    "            non_events = len(embeddings_non1)\n",
    "            n_types = 2\n",
    "            lambda_uv_t_non_events = torch.zeros(non_events * n_types)\n",
    "            embeddings_non1 = torch.stack(embeddings_non1, dim=0)\n",
    "            embeddings_non2 = torch.stack(embeddings_non2, dim=0)\n",
    "            idx = None\n",
    "            empty_t = torch.zeros(non_events, dtype=torch.long)\n",
    "            types_lst = torch.arange(n_types)\n",
    "            for k in types_lst:\n",
    "                if idx is None:\n",
    "                    idx = np.arange(non_events)\n",
    "                else:\n",
    "                    idx += non_events\n",
    "                lambda_uv_t_non_events[idx] = self.intensity_rate_lambda(embeddings_non1, embeddings_non2, empty_t + k)\n",
    "\n",
    "            # update only once per batch\n",
    "            for it, k in enumerate(event_types):\n",
    "                u_it, v_it = u_all[it], v_all[it]\n",
    "                self.update_S_A(u_it, v_it, k.item(), node_degrees[it], lambda_uv_t[it].item())\n",
    "                # def update_S_A(A,S, u, v, k, node_degree, lambda_uv_t, N_nodes,n_assoc_types,node_degree_global)\n",
    "\n",
    "        else:\n",
    "            lambda_uv_t = torch.cat(lambda_uv_t)\n",
    "            lambda_uv_t_non_events = torch.cat(lambda_uv_t_non_events)\n",
    "\n",
    "\n",
    "        if len(reg) > 1:\n",
    "            reg = [torch.stack(reg).mean()]\n",
    "\n",
    "        return lambda_uv_t, lambda_uv_t_non_events / self.N_surv_samples, [A_pred, Surv], reg\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize models node embeddings and adjacency matrices for 284 nodes\n",
      "A_initial (284, 284, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#initialise the A and z \n",
    "N_nodes = A_initial.shape[0]\n",
    "if A_initial is not None and len(A_initial.shape) == 2:\n",
    "    A_initial = A_initial[:, :, None]\n",
    "n_assoc_types,n_event_types = 1, 3\n",
    "n_relations = n_assoc_types + n_event_types\n",
    "\n",
    "Adj_all = train_set.get_Adjacency()[0]\n",
    "\n",
    "if not isinstance(Adj_all, list):\n",
    "    Adj_all = [Adj_all]\n",
    "\n",
    "node_degree_global = []\n",
    "for rel, A in enumerate(Adj_all):\n",
    "    node_degree_global.append(np.zeros(A.shape[0]))\n",
    "    for u in range(A.shape[0]):\n",
    "        node_degree_global[rel][u] = np.sum(A[u])\n",
    "\n",
    "Adj_all = Adj_all[0]\n",
    "\n",
    "# Instantiate the model\n",
    "model = DyRep(\n",
    "    node_embeddings=initial_embeddings,\n",
    "    A_initial=A_initial,\n",
    "    n_hidden=32,\n",
    "    node_degree_global=node_degree_global\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_set, batch_size=200, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# from datetime import datetime,timezone\n",
    "# for batch_idx, data in enumerate(test_loader):\n",
    "#     lambda_uv_t, lambda_uv_t_non_events, [A_pred, Surv], reg = model(data)\n",
    "#     print('lambda_uv_t', lambda_uv_t)\n",
    "#     print('lambda_uv_t_non_events', lambda_uv_t_non_events)\n",
    "#     print('A_pred', A_pred)\n",
    "#     print('Surv', Surv)\n",
    "#     print('reg', reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAR(A_pred, u, v, k, Survival_term):\n",
    "    '''Computes mean average ranking for a batch of events'''\n",
    "    ranks = []\n",
    "    hits_10 = []\n",
    "    N = len(A_pred)\n",
    "    Survival_term = torch.exp(-Survival_term)\n",
    "    A_pred *= Survival_term\n",
    "    assert torch.sum(torch.isnan(A_pred)) == 0, (torch.sum(torch.isnan(A_pred)), Survival_term.min(), Survival_term.max())\n",
    "\n",
    "    A_pred = A_pred.data.cpu().numpy()\n",
    "\n",
    "\n",
    "    assert N == len(u) == len(v) == len(k), (N, len(u), len(v), len(k))\n",
    "    for b in range(N):\n",
    "        u_it, v_it = u[b].item(), v[b].item()\n",
    "        assert u_it != v_it, (u_it, v_it, k[b])\n",
    "        A = A_pred[b].squeeze()\n",
    "        # remove same node\n",
    "        idx1 = list(np.argsort(A[u_it])[::-1])\n",
    "        idx1.remove(u_it)\n",
    "        idx2 = list(np.argsort(A[v_it])[::-1])\n",
    "        idx2.remove(v_it)\n",
    "        rank1 = np.where(np.array(idx1) == v_it) # get nodes most likely connected to u[b] and find out the rank of v[b] among those nodes\n",
    "        rank2 = np.where(np.array(idx2) == u_it)  # get nodes most likely connected to v[b] and find out the rank of u[b] among those nodes\n",
    "        assert len(rank1) == len(rank2) == 1, (len(rank1), len(rank2))\n",
    "        hits_10.append(np.mean([float(rank1[0] <= 9), float(rank2[0] <= 9)]))\n",
    "        rank = np.mean([rank1[0], rank2[0]])\n",
    "        assert isinstance(rank, np.float64), (rank, rank1, rank2, u_it, v_it, idx1, idx2)\n",
    "        ranks.append(rank)\n",
    "    return ranks, hits_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def test(model, n_test_batches=10, epoch=0):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    losses =[ [np.Inf, 0], [np.Inf, 0] ]\n",
    "    n_samples = 0\n",
    "    # Time slots with 10 days intervals as in the DyRep paper\n",
    "    timeslots = [t.toordinal() for t in test_loader.dataset.TEST_TIMESLOTS]\n",
    "    event_types = list(test_loader.dataset.event_types_num.keys()) #['comm', 'assoc']\n",
    "    # sort it by k\n",
    "    for event_t in test_loader.dataset.event_types_num:\n",
    "        event_types[test_loader.dataset.event_types_num[event_t]] = event_t\n",
    "\n",
    "    event_types += ['Com']\n",
    "\n",
    "    mar, hits_10 = {}, {}\n",
    "    for event_t in event_types:\n",
    "        mar[event_t] = []\n",
    "        hits_10[event_t] = []\n",
    "        for c, slot in enumerate(timeslots):\n",
    "            mar[event_t].append([])\n",
    "            hits_10[event_t].append([])\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        import datetime\n",
    "        #from datetime import datetime, timezone \n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            data[2] = data[2].float()\n",
    "            data[4] = data[4].double()\n",
    "            data[5] = data[5].double()\n",
    "            output = model(data)\n",
    "            loss += (-torch.sum(torch.log(output[0]) + 1e-10) + torch.sum(output[1])).item()\n",
    "            for i in range(len(losses)):\n",
    "                m1 = output[i].min()\n",
    "                m2 = output[i].max()\n",
    "                if m1 < losses[i][0]:\n",
    "                    losses[i][0] = m1\n",
    "                if m2 > losses[i][1]:\n",
    "                    losses[i][1] = m2\n",
    "            n_samples += 1\n",
    "            A_pred, Survival_term = output[2]\n",
    "            u, v, k = data[0], data[1], data[3]\n",
    "\n",
    "            time_cur = data[5]\n",
    "            m, h = MAR(A_pred, u, v, k, Survival_term=Survival_term)\n",
    "            assert len(time_cur) == len(m) == len(h) == len(k)\n",
    "            for t, m, h, k_ in zip(time_cur, m, h, k):\n",
    "                d = datetime.datetime.fromtimestamp(t.item()).toordinal()\n",
    "                event_t = event_types[k_.item()]\n",
    "                for c, slot in enumerate(timeslots):\n",
    "                    if d <= slot:\n",
    "                        mar[event_t][c].append(m)\n",
    "                        hits_10[event_t][c].append(h)\n",
    "                        if k_ > 0:\n",
    "                            mar['Com'][c].append(m)\n",
    "                            hits_10['Com'][c].append(h)\n",
    "                        if c > 0:\n",
    "                            assert slot > timeslots[c-1] and d > timeslots[c-1], (d, slot, timeslots[c-1])\n",
    "                        break\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('test', batch_idx)\n",
    "\n",
    "            if n_test_batches is not None and batch_idx >= n_test_batches - 1:\n",
    "                break\n",
    "\n",
    "    time_iter = time.time() - start\n",
    "\n",
    "    print('\\nTEST batch={}/{}, loss={:.3f}, psi={}, loss1 min/max={:.4f}/{:.4f}, '\n",
    "          'loss2 min/max={:.4f}/{:.4f}, integral time stamps={}, sec/iter={:.4f}'.\n",
    "          format(batch_idx + 1, len(test_loader), (loss / n_samples),\n",
    "                 [model.psi[c].item() for c in range(len(model.psi))],\n",
    "                 losses[0][0], losses[0][1], losses[1][0], losses[1][1],\n",
    "                 len(model.Lambda_dict), time_iter / (batch_idx + 1)))\n",
    "\n",
    "    # Report results for different time slots in the test set\n",
    "    for c, slot in enumerate(timeslots):\n",
    "        s = 'Slot {}: '.format(c)\n",
    "        for event_t in event_types:\n",
    "            sfx = '' if event_t == event_types[-1] else ', '\n",
    "            if len(mar[event_t][c]) > 0:\n",
    "                s += '{} ({} events): MAR={:.2f}+-{:.2f}, HITS_10={:.3f}+-{:.3f}'.\\\n",
    "                    format(event_t, len(mar[event_t][c]), np.mean(mar[event_t][c]), np.std(mar[event_t][c]),\n",
    "                            np.mean(hits_10[event_t][c]), np.std(hits_10[event_t][c]))\n",
    "            else:\n",
    "                s += '{} (no events)'.format(event_t)\n",
    "            s += sfx\n",
    "        print(s)\n",
    "\n",
    "    mar_all, hits_10_all = {}, {}\n",
    "    for event_t in event_types:\n",
    "        mar_all[event_t] = []\n",
    "        hits_10_all[event_t] = []\n",
    "        for c, slot in enumerate(timeslots):\n",
    "            mar_all[event_t].extend(mar[event_t][c])\n",
    "            hits_10_all[event_t].extend(hits_10[event_t][c])\n",
    "\n",
    "    s = 'Epoch {}: results per event type for all test time slots: \\n'.format(epoch)\n",
    "    print(''.join(['-']*100))\n",
    "    for event_t in event_types:\n",
    "        if len(mar_all[event_t]) > 0:\n",
    "            s += '====== {:10s}\\t ({:7s} events): \\tMAR={:.2f}+-{:.2f}\\t HITS_10={:.3f}+-{:.3f}'.\\\n",
    "                format(event_t, str(len(mar_all[event_t])), np.mean(mar_all[event_t]), np.std(mar_all[event_t]),\n",
    "                       np.mean(hits_10_all[event_t]), np.std(hits_10_all[event_t]))\n",
    "        else:\n",
    "            s += '====== {:10s}\\t (no events)'.format(event_t)\n",
    "        if event_t != event_types[-1]:\n",
    "            s += '\\n'\n",
    "    print(s)\n",
    "    print(''.join(['-'] * 100))\n",
    "\n",
    "    return mar_all, hits_10_all, loss / n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model DyRep(\n",
      "  (W_h): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (W_struct): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (W_rec): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (W_t): Linear(in_features=4, out_features=32, bias=True)\n",
      "  (omega): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('model', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_main = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        params_main.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([{\"params\": params_main, \"weight_decay\":0}], lr=0.0002, betas=(0.5, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, '10', gamma=0.5)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3,4], gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bar = np.zeros((N_nodes, 1)) + train_set.FIRST_DATE.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def get_temporal_variables():\n",
    "    variables = {}\n",
    "    variables['time_bar'] = copy.deepcopy(time_bar)\n",
    "    variables['node_degree_global'] = copy.deepcopy(node_degree_global)\n",
    "    variables['time_keys'] = copy.deepcopy(model.time_keys)\n",
    "    variables['z'] = model.z.clone()\n",
    "    variables['S'] = model.S.clone()\n",
    "    variables['A'] = model.A.clone()\n",
    "    variables['Lambda_dict'] = model.Lambda_dict.clone()\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_temporal_variables(variables, model, train_loader, test_loader):\n",
    "    time_bar = copy.deepcopy(variables['time_bar'])\n",
    "    train_loader.dataset.time_bar = time_bar\n",
    "    test_loader.dataset.time_bar = time_bar\n",
    "    model.node_degree_global = copy.deepcopy(variables['node_degree_global'])\n",
    "    model.time_keys = copy.deepcopy(variables['time_keys'])\n",
    "    model.z = variables['z'].clone()\n",
    "    model.S = variables['S'].clone()\n",
    "    model.A = variables['A'].clone()\n",
    "    model.Lambda_dict = variables['Lambda_dict'].clone()\n",
    "    return time_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# from datetime import datetime, timezone \n",
    "# for batch, dat in enumerate(train_loader):\n",
    "#     dat[2] = dat[2].float()\n",
    "#     dat[4] = dat[4].double()\n",
    "#     dat[5] = dat[5].double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initalize_state(dataset, keepS=False):\n",
    "        '''Initializes node embeddings and the graph to the original state after every epoch'''\n",
    "        Adj_all = dataset.get_Adjacency()[0]\n",
    "\n",
    "        if not isinstance(Adj_all, list):\n",
    "            Adj_all = [Adj_all]\n",
    "\n",
    "        node_degree_global = []\n",
    "        for rel, A in enumerate(Adj_all):\n",
    "            node_degree_global.append(np.zeros(A.shape[0]))\n",
    "            for u in range(A.shape[0]):\n",
    "                node_degree_global[rel][u] = np.sum(A[u])\n",
    "\n",
    "        Adj_all = Adj_all[0]\n",
    "        print('Adj_all', Adj_all.shape, len(node_degree_global), node_degree_global[0].min(), node_degree_global[0].max())\n",
    "        time_bar = np.zeros((dataset.N_nodes, 1)) + dataset.FIRST_DATE.timestamp()\n",
    "\n",
    "        model.initialize(node_embeddings=initial_embeddings,\n",
    "                         A_initial=Adj_all, keepS=keepS)  # train_loader.dataset.H_train\n",
    "\n",
    "        return time_bar, node_degree_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start = 1\n",
    "# 记得改回5\n",
    "epochs = 5\n",
    "batch_start = 0\n",
    "batch_size = 200\n",
    "weight = 1\n",
    "log_interval = 20\n",
    "losses_events, losses_nonevents, losses_KL, losses_sum = [], [], [], []\n",
    "test_MAR, test_HITS10, test_loss = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# from datetime import datetime, timezone\n",
    "# for batch_idx, data_batch in enumerate(train_loader):\n",
    "#         # if batch_idx <= batch_start:\n",
    "#         #     continue\n",
    "\n",
    "#         model.train()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Ensure the data is in the correct format\n",
    "#         data_batch[2] = data_batch[2].float()\n",
    "#         data_batch[4] = data_batch[4].double()\n",
    "#         data_batch[5] = data_batch[5].double()\n",
    "\n",
    "#         output = model(data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: time_keys is empty. No operations performed.\n",
      "\n",
      "TRAIN epoch=1/5, batch=20/59, sec/iter: 18.2825, loss=5.033, loss components: [801.5442504882812, 205.1068878173828]\n",
      "time 2013-04-10 14:13:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/0v2zn4w16nbbv578tpkxbmhr0000gn/T/ipykernel_94541/1088651520.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  hits_10.append(np.mean([float(rank1[0] <= 9), float(rank2[0] <= 9)]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0\n",
      "\n",
      "TEST batch=10/46, loss=1010.884, psi=[0.5033290982246399, 0.5040292739868164], loss1 min/max=0.0067/1.3846, loss2 min/max=0.0006/0.4567, integral time stamps=5000, sec/iter=33.8384\n",
      "Slot 0: FollowEvent (2 events): MAR=162.00+-44.00, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=136.25+-49.75, HITS_10=0.000+-0.000, PushEvent (15 events): MAR=208.53+-28.34, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=149.58+-59.42, HITS_10=0.019+-0.096, IssuesEvent (2 events): MAR=73.25+-10.25, HITS_10=0.000+-0.000, IssueCommentEvent (4 events): MAR=92.12+-64.17, HITS_10=0.125+-0.217, PullRequestEvent (5 events): MAR=179.20+-51.38, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=161.12+-62.84, HITS_10=0.019+-0.094\n",
      "Slot 1: FollowEvent (109 events): MAR=116.46+-54.97, HITS_10=0.050+-0.151, ForkEvent (101 events): MAR=150.21+-63.18, HITS_10=0.020+-0.098, PushEvent (75 events): MAR=164.67+-61.51, HITS_10=0.000+-0.000, WatchEvent (930 events): MAR=117.65+-59.99, HITS_10=0.039+-0.138, IssuesEvent (144 events): MAR=183.61+-64.80, HITS_10=0.000+-0.000, IssueCommentEvent (409 events): MAR=178.57+-64.26, HITS_10=0.006+-0.055, PullRequestEvent (123 events): MAR=174.68+-64.77, HITS_10=0.004+-0.045, CommitCommentEvent (19 events): MAR=138.55+-66.40, HITS_10=0.026+-0.112, Com (1801 events): MAR=144.66+-68.45, HITS_10=0.023+-0.107\n",
      "Slot 2: FollowEvent (2 events): MAR=130.25+-47.75, HITS_10=0.000+-0.000, ForkEvent (5 events): MAR=140.40+-60.05, HITS_10=0.000+-0.000, PushEvent (1 events): MAR=130.50+-0.00, HITS_10=0.000+-0.000, WatchEvent (21 events): MAR=104.79+-61.66, HITS_10=0.024+-0.106, IssuesEvent (1 events): MAR=58.50+-0.00, HITS_10=0.000+-0.000, IssueCommentEvent (2 events): MAR=222.75+-10.25, HITS_10=0.000+-0.000, PullRequestEvent (2 events): MAR=77.00+-19.00, HITS_10=0.250+-0.250, CommitCommentEvent (no events), Com (32 events): MAR=115.34+-64.65, HITS_10=0.031+-0.121\n",
      "Slot 3: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 4: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 5: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1: results per event type for all test time slots: \n",
      "====== FollowEvent\t (113     events): \tMAR=117.51+-55.03\t HITS_10=0.049+-0.148\n",
      "====== ForkEvent \t (108     events): \tMAR=149.50+-62.87\t HITS_10=0.019+-0.094\n",
      "====== PushEvent \t (91      events): \tMAR=171.53+-59.44\t HITS_10=0.000+-0.000\n",
      "====== WatchEvent\t (977     events): \tMAR=118.23+-60.26\t HITS_10=0.038+-0.136\n",
      "====== IssuesEvent\t (147     events): \tMAR=181.26+-66.20\t HITS_10=0.000+-0.000\n",
      "====== IssueCommentEvent\t (415     events): \tMAR=177.95+-64.74\t HITS_10=0.007+-0.060\n",
      "====== PullRequestEvent\t (130     events): \tMAR=173.35+-64.97\t HITS_10=0.008+-0.062\n",
      "====== CommitCommentEvent\t (19      events): \tMAR=138.55+-66.40\t HITS_10=0.026+-0.112\n",
      "====== Com       \t (1887    events): \tMAR=144.64+-68.40\t HITS_10=0.023+-0.107\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TRAIN epoch=1/5, batch=40/59, sec/iter: 34.4150, loss=4.703, loss components: [684.35205078125, 256.17340087890625]\n",
      "time 2013-06-30 03:40:38\n",
      "test 0\n",
      "\n",
      "TEST batch=10/46, loss=909.105, psi=[0.5062964558601379, 0.5075770616531372], loss1 min/max=0.0101/0.7918, loss2 min/max=0.0018/0.2759, integral time stamps=5000, sec/iter=38.1053\n",
      "Slot 0: FollowEvent (2 events): MAR=123.50+-22.50, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=109.25+-39.75, HITS_10=0.000+-0.000, PushEvent (15 events): MAR=192.17+-38.79, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=127.33+-64.76, HITS_10=0.058+-0.160, IssuesEvent (2 events): MAR=50.25+-8.25, HITS_10=0.500+-0.000, IssueCommentEvent (4 events): MAR=114.62+-32.36, HITS_10=0.000+-0.000, PullRequestEvent (5 events): MAR=168.10+-55.69, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=144.65+-64.26, HITS_10=0.046+-0.145\n",
      "Slot 1: FollowEvent (109 events): MAR=116.10+-59.91, HITS_10=0.124+-0.226, ForkEvent (101 events): MAR=140.84+-66.90, HITS_10=0.040+-0.135, PushEvent (75 events): MAR=158.95+-62.54, HITS_10=0.027+-0.112, WatchEvent (930 events): MAR=111.41+-59.56, HITS_10=0.067+-0.172, IssuesEvent (144 events): MAR=179.18+-65.63, HITS_10=0.010+-0.071, IssueCommentEvent (409 events): MAR=173.44+-65.57, HITS_10=0.012+-0.077, PullRequestEvent (123 events): MAR=170.24+-64.07, HITS_10=0.004+-0.045, CommitCommentEvent (19 events): MAR=127.58+-71.30, HITS_10=0.053+-0.223, Com (1801 events): MAR=138.74+-69.11, HITS_10=0.042+-0.141\n",
      "Slot 2: FollowEvent (2 events): MAR=146.75+-46.25, HITS_10=0.000+-0.000, ForkEvent (5 events): MAR=133.90+-66.10, HITS_10=0.000+-0.000, PushEvent (1 events): MAR=121.00+-0.00, HITS_10=0.000+-0.000, WatchEvent (21 events): MAR=102.29+-57.96, HITS_10=0.024+-0.106, IssuesEvent (1 events): MAR=26.00+-0.00, HITS_10=0.000+-0.000, IssueCommentEvent (2 events): MAR=218.00+-11.50, HITS_10=0.000+-0.000, PullRequestEvent (2 events): MAR=69.50+-18.00, HITS_10=0.250+-0.250, CommitCommentEvent (no events), Com (32 events): MAR=110.61+-64.03, HITS_10=0.031+-0.121\n",
      "Slot 3: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 4: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 5: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1: results per event type for all test time slots: \n",
      "====== FollowEvent\t (113     events): \tMAR=116.77+-59.38\t HITS_10=0.119+-0.223\n",
      "====== ForkEvent \t (108     events): \tMAR=139.94+-66.61\t HITS_10=0.037+-0.131\n",
      "====== PushEvent \t (91      events): \tMAR=164.01+-60.37\t HITS_10=0.022+-0.102\n",
      "====== WatchEvent\t (977     events): \tMAR=111.64+-59.74\t HITS_10=0.066+-0.171\n",
      "====== IssuesEvent\t (147     events): \tMAR=176.39+-67.81\t HITS_10=0.017+-0.091\n",
      "====== IssueCommentEvent\t (415     events): \tMAR=173.09+-65.50\t HITS_10=0.012+-0.077\n",
      "====== PullRequestEvent\t (130     events): \tMAR=168.61+-64.52\t HITS_10=0.008+-0.062\n",
      "====== CommitCommentEvent\t (19      events): \tMAR=127.58+-71.30\t HITS_10=0.053+-0.223\n",
      "====== Com       \t (1887    events): \tMAR=138.43+-69.00\t HITS_10=0.042+-0.141\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TRAIN epoch=1/5, batch=59/59, sec/iter: 40.9326, loss=0.565, loss components: [74.32198333740234, 38.61419677734375]\n",
      "time 2013-08-31 23:56:55\n",
      "test 0\n",
      "test 10\n",
      "test 20\n",
      "test 30\n",
      "test 40\n",
      "\n",
      "TEST batch=46/46, loss=835.193, psi=[0.5087382793426514, 0.5103837251663208], loss1 min/max=0.0158/0.9167, loss2 min/max=0.0017/0.2834, integral time stamps=5000, sec/iter=33.4170\n",
      "Slot 0: FollowEvent (2 events): MAR=119.25+-16.25, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=113.50+-46.50, HITS_10=0.000+-0.000, PushEvent (15 events): MAR=209.10+-32.75, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=131.15+-61.21, HITS_10=0.058+-0.160, IssuesEvent (2 events): MAR=27.50+-23.00, HITS_10=0.750+-0.250, IssueCommentEvent (4 events): MAR=132.25+-75.15, HITS_10=0.125+-0.217, PullRequestEvent (5 events): MAR=175.90+-56.01, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=152.54+-68.82, HITS_10=0.065+-0.194\n",
      "Slot 1: FollowEvent (109 events): MAR=114.23+-57.47, HITS_10=0.147+-0.247, ForkEvent (101 events): MAR=140.31+-65.55, HITS_10=0.064+-0.167, PushEvent (75 events): MAR=162.98+-63.68, HITS_10=0.033+-0.125, WatchEvent (930 events): MAR=110.56+-60.98, HITS_10=0.099+-0.205, IssuesEvent (144 events): MAR=183.18+-68.38, HITS_10=0.024+-0.123, IssueCommentEvent (409 events): MAR=175.03+-68.88, HITS_10=0.022+-0.103, PullRequestEvent (123 events): MAR=173.62+-67.13, HITS_10=0.020+-0.099, CommitCommentEvent (19 events): MAR=132.08+-72.91, HITS_10=0.079+-0.244, Com (1801 events): MAR=139.39+-71.55, HITS_10=0.066+-0.174\n",
      "Slot 2: FollowEvent (101 events): MAR=115.42+-61.21, HITS_10=0.114+-0.232, ForkEvent (116 events): MAR=136.28+-59.24, HITS_10=0.065+-0.180, PushEvent (100 events): MAR=191.65+-56.52, HITS_10=0.010+-0.070, WatchEvent (880 events): MAR=105.66+-57.13, HITS_10=0.111+-0.218, IssuesEvent (145 events): MAR=177.80+-63.70, HITS_10=0.031+-0.121, IssueCommentEvent (351 events): MAR=166.90+-69.37, HITS_10=0.038+-0.138, PullRequestEvent (87 events): MAR=165.48+-66.20, HITS_10=0.052+-0.152, CommitCommentEvent (26 events): MAR=172.65+-58.52, HITS_10=0.058+-0.160, Com (1705 events): MAR=135.60+-69.20, HITS_10=0.076+-0.188\n",
      "Slot 3: FollowEvent (152 events): MAR=113.78+-63.73, HITS_10=0.155+-0.270, ForkEvent (94 events): MAR=131.76+-65.96, HITS_10=0.064+-0.167, PushEvent (52 events): MAR=183.60+-64.82, HITS_10=0.010+-0.069, WatchEvent (887 events): MAR=107.50+-59.05, HITS_10=0.138+-0.227, IssuesEvent (102 events): MAR=161.45+-67.83, HITS_10=0.020+-0.097, IssueCommentEvent (362 events): MAR=162.18+-68.52, HITS_10=0.048+-0.152, PullRequestEvent (86 events): MAR=144.23+-62.65, HITS_10=0.035+-0.127, CommitCommentEvent (35 events): MAR=162.93+-87.08, HITS_10=0.029+-0.116, Com (1618 events): MAR=130.14+-68.63, HITS_10=0.094+-0.198\n",
      "Slot 4: FollowEvent (51 events): MAR=106.37+-62.18, HITS_10=0.088+-0.191, ForkEvent (93 events): MAR=124.17+-65.94, HITS_10=0.059+-0.161, PushEvent (92 events): MAR=201.44+-64.03, HITS_10=0.022+-0.102, WatchEvent (817 events): MAR=107.56+-58.30, HITS_10=0.111+-0.211, IssuesEvent (154 events): MAR=190.25+-71.18, HITS_10=0.029+-0.117, IssueCommentEvent (521 events): MAR=189.40+-68.65, HITS_10=0.027+-0.113, PullRequestEvent (149 events): MAR=193.15+-66.11, HITS_10=0.013+-0.081, CommitCommentEvent (25 events): MAR=172.74+-65.69, HITS_10=0.020+-0.098, Com (1851 events): MAR=150.75+-75.95, HITS_10=0.065+-0.169\n",
      "Slot 5: FollowEvent (no events), ForkEvent (57 events): MAR=134.02+-58.72, HITS_10=0.070+-0.174, PushEvent (65 events): MAR=211.25+-62.65, HITS_10=0.038+-0.133, WatchEvent (829 events): MAR=112.56+-59.40, HITS_10=0.108+-0.209, IssuesEvent (120 events): MAR=206.82+-64.37, HITS_10=0.013+-0.078, IssueCommentEvent (439 events): MAR=187.09+-70.12, HITS_10=0.025+-0.109, PullRequestEvent (120 events): MAR=185.44+-65.91, HITS_10=0.017+-0.090, CommitCommentEvent (25 events): MAR=175.34+-81.26, HITS_10=0.040+-0.136, Com (1655 events): MAR=150.01+-74.95, HITS_10=0.067+-0.172\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1: results per event type for all test time slots: \n",
      "====== FollowEvent\t (415     events): \tMAR=113.41+-61.24\t HITS_10=0.134+-0.247\n",
      "====== ForkEvent \t (463     events): \tMAR=133.43+-63.55\t HITS_10=0.064+-0.170\n",
      "====== PushEvent \t (399     events): \tMAR=191.32+-63.20\t HITS_10=0.021+-0.101\n",
      "====== WatchEvent\t (4369    events): \tMAR=108.89+-59.10\t HITS_10=0.113+-0.214\n",
      "====== IssuesEvent\t (667     events): \tMAR=184.11+-69.10\t HITS_10=0.026+-0.118\n",
      "====== IssueCommentEvent\t (2086    events): \tMAR=177.48+-69.98\t HITS_10=0.031+-0.123\n",
      "====== PullRequestEvent\t (570     events): \tMAR=175.56+-67.71\t HITS_10=0.025+-0.108\n",
      "====== CommitCommentEvent\t (130     events): \tMAR=164.64+-76.20\t HITS_10=0.042+-0.152\n",
      "====== Com       \t (8684    events): \tMAR=141.45+-72.62\t HITS_10=0.073+-0.181\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Adj_all (284, 284) 1 0.0 15.0\n",
      "initialize models node embeddings and adjacency matrices for 284 nodes\n",
      "A_initial (284, 284)\n",
      "Warning: time_keys is empty. No operations performed.\n",
      "\n",
      "TRAIN epoch=2/5, batch=20/59, sec/iter: 18.0865, loss=3.904, loss components: [438.4562072753906, 342.3735046386719]\n",
      "time 2013-04-10 14:13:33\n",
      "test 0\n",
      "\n",
      "TEST batch=10/46, loss=798.405, psi=[0.5112947225570679, 0.5127304792404175], loss1 min/max=0.0163/1.5608, loss2 min/max=0.0010/0.4339, integral time stamps=5000, sec/iter=33.9193\n",
      "Slot 0: FollowEvent (2 events): MAR=147.50+-26.50, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=121.75+-53.75, HITS_10=0.000+-0.000, PushEvent (15 events): MAR=206.33+-29.84, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=140.69+-58.78, HITS_10=0.058+-0.160, IssuesEvent (2 events): MAR=55.50+-9.50, HITS_10=0.250+-0.250, IssueCommentEvent (4 events): MAR=83.62+-57.96, HITS_10=0.125+-0.217, PullRequestEvent (5 events): MAR=174.00+-51.04, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=153.93+-64.49, HITS_10=0.046+-0.145\n",
      "Slot 1: FollowEvent (109 events): MAR=108.89+-55.86, HITS_10=0.115+-0.210, ForkEvent (101 events): MAR=141.06+-63.90, HITS_10=0.050+-0.149, PushEvent (75 events): MAR=157.50+-60.87, HITS_10=0.027+-0.112, WatchEvent (930 events): MAR=107.44+-58.46, HITS_10=0.110+-0.211, IssuesEvent (144 events): MAR=174.78+-66.60, HITS_10=0.021+-0.100, IssueCommentEvent (409 events): MAR=167.63+-66.43, HITS_10=0.021+-0.100, PullRequestEvent (123 events): MAR=165.26+-64.94, HITS_10=0.016+-0.089, CommitCommentEvent (19 events): MAR=126.00+-68.10, HITS_10=0.026+-0.112, Com (1801 events): MAR=134.61+-68.47, HITS_10=0.069+-0.174\n",
      "Slot 2: FollowEvent (2 events): MAR=136.00+-48.00, HITS_10=0.000+-0.000, ForkEvent (5 events): MAR=137.60+-63.88, HITS_10=0.000+-0.000, PushEvent (1 events): MAR=123.50+-0.00, HITS_10=0.000+-0.000, WatchEvent (21 events): MAR=97.55+-55.57, HITS_10=0.095+-0.196, IssuesEvent (1 events): MAR=26.00+-0.00, HITS_10=0.500+-0.000, IssueCommentEvent (2 events): MAR=221.50+-10.50, HITS_10=0.000+-0.000, PullRequestEvent (2 events): MAR=70.50+-20.00, HITS_10=0.250+-0.250, CommitCommentEvent (no events), Com (32 events): MAR=108.44+-63.36, HITS_10=0.094+-0.195\n",
      "Slot 3: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 4: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 5: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 2: results per event type for all test time slots: \n",
      "====== FollowEvent\t (113     events): \tMAR=110.06+-55.69\t HITS_10=0.111+-0.208\n",
      "====== ForkEvent \t (108     events): \tMAR=140.55+-63.78\t HITS_10=0.046+-0.145\n",
      "====== PushEvent \t (91      events): \tMAR=165.18+-59.56\t HITS_10=0.022+-0.102\n",
      "====== WatchEvent\t (977     events): \tMAR=108.11+-58.67\t HITS_10=0.108+-0.210\n",
      "====== IssuesEvent\t (147     events): \tMAR=172.15+-68.44\t HITS_10=0.027+-0.113\n",
      "====== IssueCommentEvent\t (415     events): \tMAR=167.08+-66.81\t HITS_10=0.022+-0.102\n",
      "====== PullRequestEvent\t (130     events): \tMAR=164.14+-65.09\t HITS_10=0.019+-0.096\n",
      "====== CommitCommentEvent\t (19      events): \tMAR=126.00+-68.10\t HITS_10=0.026+-0.112\n",
      "====== Com       \t (1887    events): \tMAR=134.72+-68.44\t HITS_10=0.068+-0.174\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TRAIN epoch=2/5, batch=40/59, sec/iter: 34.2875, loss=3.973, loss components: [364.24993896484375, 430.3675842285156]\n",
      "time 2013-06-30 03:40:38\n",
      "test 0\n",
      "\n",
      "TEST batch=10/46, loss=778.109, psi=[0.5132858157157898, 0.5145725011825562], loss1 min/max=0.0331/1.1567, loss2 min/max=0.0039/0.3111, integral time stamps=5000, sec/iter=38.0346\n",
      "Slot 0: FollowEvent (2 events): MAR=122.50+-18.50, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=102.50+-55.50, HITS_10=0.000+-0.000, PushEvent (15 events): MAR=193.87+-43.91, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=120.77+-64.90, HITS_10=0.077+-0.180, IssuesEvent (2 events): MAR=51.75+-8.25, HITS_10=0.500+-0.000, IssueCommentEvent (4 events): MAR=108.00+-34.39, HITS_10=0.000+-0.000, PullRequestEvent (5 events): MAR=167.60+-56.17, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=141.23+-67.30, HITS_10=0.056+-0.157\n",
      "Slot 1: FollowEvent (109 events): MAR=109.35+-61.08, HITS_10=0.151+-0.240, ForkEvent (101 events): MAR=136.09+-66.85, HITS_10=0.084+-0.187, PushEvent (75 events): MAR=157.28+-63.68, HITS_10=0.047+-0.145, WatchEvent (930 events): MAR=104.46+-58.76, HITS_10=0.148+-0.232, IssuesEvent (144 events): MAR=175.31+-69.61, HITS_10=0.031+-0.121, IssueCommentEvent (409 events): MAR=167.54+-69.34, HITS_10=0.049+-0.149, PullRequestEvent (123 events): MAR=166.50+-65.64, HITS_10=0.037+-0.130, CommitCommentEvent (19 events): MAR=118.32+-69.04, HITS_10=0.105+-0.261, Com (1801 events): MAR=132.80+-70.46, HITS_10=0.100+-0.203\n",
      "Slot 2: FollowEvent (2 events): MAR=142.50+-48.50, HITS_10=0.000+-0.000, ForkEvent (5 events): MAR=136.90+-64.90, HITS_10=0.000+-0.000, PushEvent (1 events): MAR=121.00+-0.00, HITS_10=0.000+-0.000, WatchEvent (21 events): MAR=96.00+-54.21, HITS_10=0.119+-0.213, IssuesEvent (1 events): MAR=24.00+-0.00, HITS_10=0.500+-0.000, IssueCommentEvent (2 events): MAR=222.75+-13.25, HITS_10=0.000+-0.000, PullRequestEvent (2 events): MAR=70.00+-18.50, HITS_10=0.250+-0.250, CommitCommentEvent (no events), Com (32 events): MAR=107.22+-63.11, HITS_10=0.109+-0.207\n",
      "Slot 3: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 4: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 5: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 2: results per event type for all test time slots: \n",
      "====== FollowEvent\t (113     events): \tMAR=110.17+-60.57\t HITS_10=0.146+-0.237\n",
      "====== ForkEvent \t (108     events): \tMAR=135.50+-66.73\t HITS_10=0.079+-0.182\n",
      "====== PushEvent \t (91      events): \tMAR=162.91+-62.15\t HITS_10=0.038+-0.133\n",
      "====== WatchEvent\t (977     events): \tMAR=104.71+-58.91\t HITS_10=0.145+-0.230\n",
      "====== IssuesEvent\t (147     events): \tMAR=172.60+-71.44\t HITS_10=0.041+-0.137\n",
      "====== IssueCommentEvent\t (415     events): \tMAR=167.23+-69.28\t HITS_10=0.048+-0.148\n",
      "====== PullRequestEvent\t (130     events): \tMAR=165.05+-65.92\t HITS_10=0.038+-0.133\n",
      "====== CommitCommentEvent\t (19      events): \tMAR=118.32+-69.04\t HITS_10=0.105+-0.261\n",
      "====== Com       \t (1887    events): \tMAR=132.61+-70.35\t HITS_10=0.099+-0.202\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TRAIN epoch=2/5, batch=59/59, sec/iter: 40.9246, loss=0.521, loss components: [37.92620086669922, 66.32139587402344]\n",
      "time 2013-08-31 23:56:55\n",
      "test 0\n",
      "test 10\n",
      "test 20\n",
      "test 30\n",
      "test 40\n",
      "\n",
      "TEST batch=46/46, loss=781.786, psi=[0.514732837677002, 0.5157469511032104], loss1 min/max=0.0350/1.3222, loss2 min/max=0.0043/0.3241, integral time stamps=5000, sec/iter=33.3776\n",
      "Slot 0: FollowEvent (2 events): MAR=113.00+-22.00, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=104.00+-61.00, HITS_10=0.000+-0.000, PushEvent (15 events): MAR=212.73+-36.27, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=128.60+-64.05, HITS_10=0.038+-0.133, IssuesEvent (2 events): MAR=26.75+-25.25, HITS_10=0.750+-0.250, IssueCommentEvent (4 events): MAR=136.12+-76.84, HITS_10=0.125+-0.217, PullRequestEvent (5 events): MAR=175.10+-58.22, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=152.15+-72.64, HITS_10=0.056+-0.184\n",
      "Slot 1: FollowEvent (109 events): MAR=109.01+-57.78, HITS_10=0.151+-0.240, ForkEvent (101 events): MAR=138.99+-67.09, HITS_10=0.109+-0.206, PushEvent (75 events): MAR=164.55+-64.98, HITS_10=0.047+-0.145, WatchEvent (930 events): MAR=106.19+-60.59, HITS_10=0.172+-0.245, IssuesEvent (144 events): MAR=180.89+-72.31, HITS_10=0.059+-0.172, IssueCommentEvent (409 events): MAR=171.35+-71.75, HITS_10=0.070+-0.173, PullRequestEvent (123 events): MAR=172.17+-68.68, HITS_10=0.045+-0.143, CommitCommentEvent (19 events): MAR=127.37+-72.28, HITS_10=0.105+-0.261, Com (1801 events): MAR=135.96+-72.92, HITS_10=0.122+-0.220\n",
      "Slot 2: FollowEvent (101 events): MAR=109.47+-58.80, HITS_10=0.134+-0.243, ForkEvent (116 events): MAR=133.91+-60.70, HITS_10=0.108+-0.216, PushEvent (100 events): MAR=190.29+-59.77, HITS_10=0.025+-0.109, WatchEvent (880 events): MAR=98.88+-55.52, HITS_10=0.194+-0.256, IssuesEvent (145 events): MAR=172.26+-66.77, HITS_10=0.048+-0.148, IssueCommentEvent (351 events): MAR=161.68+-72.44, HITS_10=0.087+-0.197, PullRequestEvent (87 events): MAR=161.55+-68.65, HITS_10=0.092+-0.194, CommitCommentEvent (26 events): MAR=167.83+-61.31, HITS_10=0.096+-0.197, Com (1705 events): MAR=130.04+-70.38, HITS_10=0.137+-0.232\n",
      "Slot 3: FollowEvent (152 events): MAR=108.28+-63.31, HITS_10=0.204+-0.289, ForkEvent (94 events): MAR=126.19+-63.66, HITS_10=0.117+-0.212, PushEvent (52 events): MAR=178.12+-67.50, HITS_10=0.048+-0.147, WatchEvent (887 events): MAR=102.25+-57.11, HITS_10=0.223+-0.257, IssuesEvent (102 events): MAR=154.54+-70.57, HITS_10=0.093+-0.195, IssueCommentEvent (362 events): MAR=155.17+-69.17, HITS_10=0.104+-0.206, PullRequestEvent (86 events): MAR=141.17+-62.65, HITS_10=0.081+-0.185, CommitCommentEvent (35 events): MAR=158.57+-87.10, HITS_10=0.071+-0.175, Com (1618 events): MAR=124.50+-67.81, HITS_10=0.165+-0.241\n",
      "Slot 4: FollowEvent (51 events): MAR=100.62+-59.46, HITS_10=0.157+-0.232, ForkEvent (93 events): MAR=118.37+-65.11, HITS_10=0.102+-0.215, PushEvent (92 events): MAR=197.93+-66.24, HITS_10=0.049+-0.149, WatchEvent (817 events): MAR=99.86+-55.48, HITS_10=0.197+-0.253, IssuesEvent (154 events): MAR=185.13+-73.87, HITS_10=0.055+-0.157, IssueCommentEvent (521 events): MAR=182.36+-72.63, HITS_10=0.076+-0.182, PullRequestEvent (149 events): MAR=191.81+-66.61, HITS_10=0.040+-0.148, CommitCommentEvent (25 events): MAR=162.44+-66.86, HITS_10=0.060+-0.162, Com (1851 events): MAR=144.23+-76.99, HITS_10=0.125+-0.222\n",
      "Slot 5: FollowEvent (no events), ForkEvent (57 events): MAR=123.93+-53.87, HITS_10=0.149+-0.229, PushEvent (65 events): MAR=210.23+-62.40, HITS_10=0.054+-0.155, WatchEvent (829 events): MAR=102.15+-55.82, HITS_10=0.215+-0.254, IssuesEvent (120 events): MAR=197.73+-68.52, HITS_10=0.050+-0.150, IssueCommentEvent (439 events): MAR=176.72+-73.73, HITS_10=0.073+-0.180, PullRequestEvent (120 events): MAR=181.48+-69.33, HITS_10=0.037+-0.132, CommitCommentEvent (25 events): MAR=173.38+-79.01, HITS_10=0.060+-0.215, Com (1655 events): MAR=140.68+-75.49, HITS_10=0.142+-0.230\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 2: results per event type for all test time slots: \n",
      "====== FollowEvent\t (415     events): \tMAR=107.84+-60.26\t HITS_10=0.166+-0.260\n",
      "====== ForkEvent \t (463     events): \tMAR=128.97+-63.33\t HITS_10=0.113+-0.214\n",
      "====== PushEvent \t (399     events): \tMAR=189.72+-64.96\t HITS_10=0.041+-0.138\n",
      "====== WatchEvent\t (4369    events): \tMAR=102.10+-57.16\t HITS_10=0.199+-0.253\n",
      "====== IssuesEvent\t (667     events): \tMAR=178.53+-72.17\t HITS_10=0.061+-0.169\n",
      "====== IssueCommentEvent\t (2086    events): \tMAR=170.73+-72.77\t HITS_10=0.081+-0.187\n",
      "====== PullRequestEvent\t (570     events): \tMAR=172.99+-69.37\t HITS_10=0.054+-0.158\n",
      "====== CommitCommentEvent\t (130     events): \tMAR=159.45+-76.30\t HITS_10=0.077+-0.201\n",
      "====== Com       \t (8684    events): \tMAR=135.43+-73.25\t HITS_10=0.137+-0.229\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Adj_all (284, 284) 1 0.0 15.0\n",
      "initialize models node embeddings and adjacency matrices for 284 nodes\n",
      "A_initial (284, 284)\n",
      "Warning: time_keys is empty. No operations performed.\n",
      "\n",
      "TRAIN epoch=3/5, batch=20/59, sec/iter: 18.1445, loss=3.893, loss components: [222.10487365722656, 556.4117431640625]\n",
      "time 2013-04-10 14:13:33\n",
      "test 0\n",
      "\n",
      "TEST batch=10/46, loss=806.024, psi=[0.5163775682449341, 0.5166246294975281], loss1 min/max=0.0279/1.8426, loss2 min/max=0.0021/0.4653, integral time stamps=5000, sec/iter=33.9654\n",
      "Slot 0: FollowEvent (2 events): MAR=138.50+-32.50, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=106.00+-62.50, HITS_10=0.000+-0.000, PushEvent (15 events): MAR=195.73+-31.68, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=134.71+-57.59, HITS_10=0.096+-0.197, IssuesEvent (2 events): MAR=49.25+-0.25, HITS_10=0.500+-0.000, IssueCommentEvent (4 events): MAR=82.50+-57.10, HITS_10=0.125+-0.217, PullRequestEvent (5 events): MAR=162.40+-47.98, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=146.13+-62.87, HITS_10=0.074+-0.178\n",
      "Slot 1: FollowEvent (109 events): MAR=103.27+-56.27, HITS_10=0.151+-0.230, ForkEvent (101 events): MAR=136.76+-62.63, HITS_10=0.109+-0.206, PushEvent (75 events): MAR=154.49+-59.77, HITS_10=0.033+-0.125, WatchEvent (930 events): MAR=102.31+-56.52, HITS_10=0.170+-0.241, IssuesEvent (144 events): MAR=167.18+-66.92, HITS_10=0.038+-0.133, IssueCommentEvent (409 events): MAR=159.55+-66.49, HITS_10=0.071+-0.174, PullRequestEvent (123 events): MAR=158.16+-63.29, HITS_10=0.045+-0.143, CommitCommentEvent (19 events): MAR=117.24+-67.64, HITS_10=0.079+-0.182, Com (1801 events): MAR=128.57+-66.99, HITS_10=0.118+-0.215\n",
      "Slot 2: FollowEvent (2 events): MAR=128.50+-49.00, HITS_10=0.000+-0.000, ForkEvent (5 events): MAR=133.60+-63.21, HITS_10=0.000+-0.000, PushEvent (1 events): MAR=120.00+-0.00, HITS_10=0.000+-0.000, WatchEvent (21 events): MAR=93.14+-53.83, HITS_10=0.143+-0.226, IssuesEvent (1 events): MAR=31.50+-0.00, HITS_10=0.500+-0.000, IssueCommentEvent (2 events): MAR=223.00+-10.00, HITS_10=0.000+-0.000, PullRequestEvent (2 events): MAR=73.25+-22.75, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (32 events): MAR=105.25+-62.40, HITS_10=0.109+-0.207\n",
      "Slot 3: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 4: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 5: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 3: results per event type for all test time slots: \n",
      "====== FollowEvent\t (113     events): \tMAR=104.34+-56.10\t HITS_10=0.146+-0.227\n",
      "====== ForkEvent \t (108     events): \tMAR=136.05+-62.80\t HITS_10=0.102+-0.201\n",
      "====== PushEvent \t (91      events): \tMAR=160.91+-57.98\t HITS_10=0.027+-0.114\n",
      "====== WatchEvent\t (977     events): \tMAR=102.98+-56.75\t HITS_10=0.167+-0.240\n",
      "====== IssuesEvent\t (147     events): \tMAR=164.65+-68.52\t HITS_10=0.048+-0.147\n",
      "====== IssueCommentEvent\t (415     events): \tMAR=159.11+-66.82\t HITS_10=0.071+-0.175\n",
      "====== PullRequestEvent\t (130     events): \tMAR=157.02+-63.22\t HITS_10=0.042+-0.139\n",
      "====== CommitCommentEvent\t (19      events): \tMAR=117.24+-67.64\t HITS_10=0.079+-0.182\n",
      "====== Com       \t (1887    events): \tMAR=128.68+-66.94\t HITS_10=0.117+-0.214\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TRAIN epoch=3/5, batch=40/59, sec/iter: 34.2434, loss=4.306, loss components: [192.53106689453125, 668.5722045898438]\n",
      "time 2013-06-30 03:40:38\n",
      "test 0\n",
      "\n",
      "TEST batch=10/46, loss=852.066, psi=[0.5174980163574219, 0.517069935798645], loss1 min/max=0.0616/1.5687, loss2 min/max=0.0065/0.3607, integral time stamps=5000, sec/iter=37.8555\n",
      "Slot 0: FollowEvent (2 events): MAR=110.75+-10.25, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=97.50+-75.50, HITS_10=0.000+-0.000, PushEvent (15 events): MAR=196.83+-45.58, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=118.87+-64.70, HITS_10=0.096+-0.197, IssuesEvent (2 events): MAR=53.75+-5.25, HITS_10=0.500+-0.000, IssueCommentEvent (4 events): MAR=102.62+-44.71, HITS_10=0.000+-0.000, PullRequestEvent (5 events): MAR=165.90+-54.60, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=140.47+-69.63, HITS_10=0.065+-0.168\n",
      "Slot 1: FollowEvent (109 events): MAR=105.95+-60.43, HITS_10=0.174+-0.248, ForkEvent (101 events): MAR=135.61+-65.83, HITS_10=0.119+-0.213, PushEvent (75 events): MAR=157.82+-63.98, HITS_10=0.040+-0.136, WatchEvent (930 events): MAR=102.93+-57.96, HITS_10=0.185+-0.246, IssuesEvent (144 events): MAR=173.32+-70.80, HITS_10=0.062+-0.165, IssueCommentEvent (409 events): MAR=164.83+-70.16, HITS_10=0.086+-0.188, PullRequestEvent (123 events): MAR=164.53+-65.42, HITS_10=0.053+-0.154, CommitCommentEvent (19 events): MAR=112.42+-72.74, HITS_10=0.132+-0.273, Com (1801 events): MAR=131.04+-70.26, HITS_10=0.134+-0.224\n",
      "Slot 2: FollowEvent (2 events): MAR=136.00+-51.00, HITS_10=0.000+-0.000, ForkEvent (5 events): MAR=136.20+-65.22, HITS_10=0.000+-0.000, PushEvent (1 events): MAR=121.00+-0.00, HITS_10=0.000+-0.000, WatchEvent (21 events): MAR=94.17+-52.73, HITS_10=0.143+-0.226, IssuesEvent (1 events): MAR=31.00+-0.00, HITS_10=0.500+-0.000, IssueCommentEvent (2 events): MAR=226.25+-12.75, HITS_10=0.000+-0.000, PullRequestEvent (2 events): MAR=72.25+-19.75, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (32 events): MAR=106.48+-62.58, HITS_10=0.109+-0.207\n",
      "Slot 3: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 4: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 5: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 3: results per event type for all test time slots: \n",
      "====== FollowEvent\t (113     events): \tMAR=106.57+-59.88\t HITS_10=0.168+-0.245\n",
      "====== ForkEvent \t (108     events): \tMAR=134.93+-66.19\t HITS_10=0.111+-0.208\n",
      "====== PushEvent \t (91      events): \tMAR=163.85+-62.81\t HITS_10=0.033+-0.124\n",
      "====== WatchEvent\t (977     events): \tMAR=103.16+-58.11\t HITS_10=0.182+-0.245\n",
      "====== IssuesEvent\t (147     events): \tMAR=170.73+-72.36\t HITS_10=0.071+-0.175\n",
      "====== IssueCommentEvent\t (415     events): \tMAR=164.53+-70.19\t HITS_10=0.084+-0.187\n",
      "====== PullRequestEvent\t (130     events): \tMAR=163.16+-65.57\t HITS_10=0.050+-0.150\n",
      "====== CommitCommentEvent\t (19      events): \tMAR=112.42+-72.74\t HITS_10=0.132+-0.273\n",
      "====== Com       \t (1887    events): \tMAR=130.89+-70.21\t HITS_10=0.131+-0.223\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TRAIN epoch=3/5, batch=59/59, sec/iter: 40.7968, loss=0.596, loss components: [21.209012985229492, 97.89207458496094]\n",
      "time 2013-08-31 23:56:55\n",
      "test 0\n",
      "test 10\n",
      "test 20\n",
      "test 30\n",
      "test 40\n",
      "\n",
      "TEST batch=46/46, loss=894.374, psi=[0.518268883228302, 0.5172426104545593], loss1 min/max=0.0530/1.7084, loss2 min/max=0.0057/0.3618, integral time stamps=5000, sec/iter=33.2638\n",
      "Slot 0: FollowEvent (2 events): MAR=107.25+-28.75, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=97.50+-74.00, HITS_10=0.250+-0.250, PushEvent (15 events): MAR=217.50+-36.52, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=128.48+-63.75, HITS_10=0.077+-0.180, IssuesEvent (2 events): MAR=26.50+-24.50, HITS_10=0.750+-0.250, IssueCommentEvent (4 events): MAR=142.38+-76.95, HITS_10=0.000+-0.000, PullRequestEvent (5 events): MAR=180.20+-58.26, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=154.10+-74.38, HITS_10=0.074+-0.202\n",
      "Slot 1: FollowEvent (109 events): MAR=106.95+-57.65, HITS_10=0.183+-0.250, ForkEvent (101 events): MAR=140.04+-66.39, HITS_10=0.124+-0.216, PushEvent (75 events): MAR=167.09+-65.88, HITS_10=0.033+-0.125, WatchEvent (930 events): MAR=105.98+-60.17, HITS_10=0.195+-0.250, IssuesEvent (144 events): MAR=182.32+-73.04, HITS_10=0.073+-0.186, IssueCommentEvent (409 events): MAR=171.46+-73.14, HITS_10=0.092+-0.193, PullRequestEvent (123 events): MAR=172.63+-69.22, HITS_10=0.057+-0.159, CommitCommentEvent (19 events): MAR=122.66+-74.58, HITS_10=0.132+-0.273, Com (1801 events): MAR=136.14+-73.36, HITS_10=0.141+-0.230\n",
      "Slot 2: FollowEvent (101 events): MAR=107.66+-57.95, HITS_10=0.129+-0.230, ForkEvent (116 events): MAR=133.01+-60.37, HITS_10=0.125+-0.226, PushEvent (100 events): MAR=189.60+-62.13, HITS_10=0.045+-0.143, WatchEvent (880 events): MAR=97.25+-54.25, HITS_10=0.221+-0.261, IssuesEvent (145 events): MAR=169.18+-67.54, HITS_10=0.062+-0.165, IssueCommentEvent (351 events): MAR=159.66+-73.33, HITS_10=0.110+-0.217, PullRequestEvent (87 events): MAR=160.25+-68.15, HITS_10=0.092+-0.194, CommitCommentEvent (26 events): MAR=166.33+-60.42, HITS_10=0.096+-0.197, Com (1705 events): MAR=128.34+-70.14, HITS_10=0.159+-0.242\n",
      "Slot 3: FollowEvent (152 events): MAR=105.50+-62.73, HITS_10=0.207+-0.278, ForkEvent (94 events): MAR=122.80+-60.75, HITS_10=0.122+-0.215, PushEvent (52 events): MAR=176.90+-68.18, HITS_10=0.067+-0.171, WatchEvent (887 events): MAR=101.24+-56.40, HITS_10=0.240+-0.260, IssuesEvent (102 events): MAR=151.80+-72.02, HITS_10=0.118+-0.223, IssueCommentEvent (362 events): MAR=151.15+-69.28, HITS_10=0.115+-0.213, PullRequestEvent (86 events): MAR=140.63+-63.08, HITS_10=0.093+-0.195, CommitCommentEvent (35 events): MAR=157.47+-86.88, HITS_10=0.114+-0.210, Com (1618 events): MAR=122.59+-67.14, HITS_10=0.181+-0.247\n",
      "Slot 4: FollowEvent (51 events): MAR=99.88+-59.39, HITS_10=0.176+-0.239, ForkEvent (93 events): MAR=117.24+-64.22, HITS_10=0.134+-0.233, PushEvent (92 events): MAR=194.27+-65.91, HITS_10=0.060+-0.162, WatchEvent (817 events): MAR=98.12+-53.91, HITS_10=0.217+-0.257, IssuesEvent (154 events): MAR=181.81+-73.54, HITS_10=0.068+-0.172, IssueCommentEvent (521 events): MAR=177.75+-73.26, HITS_10=0.098+-0.201, PullRequestEvent (149 events): MAR=189.42+-65.53, HITS_10=0.044+-0.153, CommitCommentEvent (25 events): MAR=158.40+-66.96, HITS_10=0.080+-0.183, Com (1851 events): MAR=141.40+-75.93, HITS_10=0.143+-0.233\n",
      "Slot 5: FollowEvent (no events), ForkEvent (57 events): MAR=119.43+-51.25, HITS_10=0.167+-0.236, PushEvent (65 events): MAR=207.95+-61.44, HITS_10=0.054+-0.155, WatchEvent (829 events): MAR=99.55+-53.99, HITS_10=0.248+-0.257, IssuesEvent (120 events): MAR=190.93+-70.31, HITS_10=0.067+-0.170, IssueCommentEvent (439 events): MAR=171.15+-73.36, HITS_10=0.093+-0.198, PullRequestEvent (120 events): MAR=178.30+-69.66, HITS_10=0.042+-0.138, CommitCommentEvent (25 events): MAR=168.62+-75.90, HITS_10=0.060+-0.215, Com (1655 events): MAR=136.87+-74.12, HITS_10=0.166+-0.240\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 3: results per event type for all test time slots: \n",
      "====== FollowEvent\t (415     events): \tMAR=105.73+-59.79\t HITS_10=0.177+-0.256\n",
      "====== ForkEvent \t (463     events): \tMAR=127.48+-62.28\t HITS_10=0.132+-0.225\n",
      "====== PushEvent \t (399     events): \tMAR=188.83+-65.27\t HITS_10=0.049+-0.148\n",
      "====== WatchEvent\t (4369    events): \tMAR=100.71+-56.08\t HITS_10=0.223+-0.258\n",
      "====== IssuesEvent\t (667     events): \tMAR=175.76+-72.80\t HITS_10=0.077+-0.187\n",
      "====== IssueCommentEvent\t (2086    events): \tMAR=167.40+-73.22\t HITS_10=0.100+-0.204\n",
      "====== PullRequestEvent\t (570     events): \tMAR=171.56+-69.10\t HITS_10=0.061+-0.166\n",
      "====== CommitCommentEvent\t (130     events): \tMAR=156.48+-75.90\t HITS_10=0.096+-0.216\n",
      "====== Com       \t (8684    events): \tMAR=133.45+-72.66\t HITS_10=0.157+-0.239\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Adj_all (284, 284) 1 0.0 15.0\n",
      "initialize models node embeddings and adjacency matrices for 284 nodes\n",
      "A_initial (284, 284)\n",
      "Warning: time_keys is empty. No operations performed.\n",
      "\n",
      "TRAIN epoch=4/5, batch=20/59, sec/iter: 18.1299, loss=4.452, loss components: [130.7442626953125, 759.7283935546875]\n",
      "time 2013-04-10 14:13:33\n",
      "test 0\n",
      "\n",
      "TEST batch=10/46, loss=930.722, psi=[0.5193406343460083, 0.5174002647399902], loss1 min/max=0.0356/1.9930, loss2 min/max=0.0010/0.5353, integral time stamps=5000, sec/iter=33.9486\n",
      "Slot 0: FollowEvent (2 events): MAR=131.25+-35.75, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=100.25+-69.25, HITS_10=0.000+-0.000, PushEvent (15 events): MAR=189.90+-32.41, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=134.15+-55.87, HITS_10=0.077+-0.180, IssuesEvent (2 events): MAR=52.50+-5.00, HITS_10=0.500+-0.000, IssueCommentEvent (4 events): MAR=84.12+-54.44, HITS_10=0.000+-0.000, PullRequestEvent (5 events): MAR=159.70+-44.64, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=144.02+-60.65, HITS_10=0.056+-0.157\n",
      "Slot 1: FollowEvent (109 events): MAR=100.64+-56.28, HITS_10=0.165+-0.235, ForkEvent (101 events): MAR=135.43+-60.21, HITS_10=0.114+-0.210, PushEvent (75 events): MAR=152.75+-59.22, HITS_10=0.033+-0.125, WatchEvent (930 events): MAR=100.76+-55.01, HITS_10=0.189+-0.247, IssuesEvent (144 events): MAR=164.32+-66.25, HITS_10=0.069+-0.173, IssueCommentEvent (409 events): MAR=156.08+-66.41, HITS_10=0.090+-0.192, PullRequestEvent (123 events): MAR=154.60+-62.72, HITS_10=0.057+-0.159, CommitCommentEvent (19 events): MAR=111.97+-68.63, HITS_10=0.105+-0.204, Com (1801 events): MAR=126.31+-65.78, HITS_10=0.137+-0.225\n",
      "Slot 2: FollowEvent (2 events): MAR=125.00+-48.50, HITS_10=0.000+-0.000, ForkEvent (5 events): MAR=130.40+-64.39, HITS_10=0.000+-0.000, PushEvent (1 events): MAR=117.50+-0.00, HITS_10=0.000+-0.000, WatchEvent (21 events): MAR=91.81+-52.99, HITS_10=0.143+-0.226, IssuesEvent (1 events): MAR=37.50+-0.00, HITS_10=0.500+-0.000, IssueCommentEvent (2 events): MAR=222.50+-10.50, HITS_10=0.000+-0.000, PullRequestEvent (2 events): MAR=71.25+-19.75, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (32 events): MAR=103.83+-61.78, HITS_10=0.109+-0.207\n",
      "Slot 3: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 4: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 5: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 4: results per event type for all test time slots: \n",
      "====== FollowEvent\t (113     events): \tMAR=101.62+-56.08\t HITS_10=0.159+-0.233\n",
      "====== ForkEvent \t (108     events): \tMAR=134.55+-60.78\t HITS_10=0.106+-0.205\n",
      "====== PushEvent \t (91      events): \tMAR=158.48+-57.20\t HITS_10=0.027+-0.114\n",
      "====== WatchEvent\t (977     events): \tMAR=101.46+-55.27\t HITS_10=0.185+-0.246\n",
      "====== IssuesEvent\t (147     events): \tMAR=161.93+-67.63\t HITS_10=0.078+-0.182\n",
      "====== IssueCommentEvent\t (415     events): \tMAR=155.70+-66.68\t HITS_10=0.089+-0.191\n",
      "====== PullRequestEvent\t (130     events): \tMAR=153.51+-62.54\t HITS_10=0.054+-0.155\n",
      "====== CommitCommentEvent\t (19      events): \tMAR=111.97+-68.63\t HITS_10=0.105+-0.204\n",
      "====== Com       \t (1887    events): \tMAR=126.44+-65.71\t HITS_10=0.134+-0.224\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TRAIN epoch=4/5, batch=40/59, sec/iter: 34.3554, loss=4.980, loss components: [124.93873596191406, 871.0628051757812]\n",
      "time 2013-06-30 03:40:38\n",
      "test 0\n",
      "\n",
      "TEST batch=10/46, loss=993.058, psi=[0.5199670195579529, 0.5173107385635376], loss1 min/max=0.0755/1.9548, loss2 min/max=0.0057/0.4055, integral time stamps=5000, sec/iter=162.2650\n",
      "Slot 0: FollowEvent (2 events): MAR=104.50+-5.50, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=104.25+-83.75, HITS_10=0.250+-0.250, PushEvent (15 events): MAR=197.60+-46.63, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=119.81+-63.43, HITS_10=0.096+-0.197, IssuesEvent (2 events): MAR=56.25+-5.25, HITS_10=0.500+-0.000, IssueCommentEvent (4 events): MAR=103.38+-49.06, HITS_10=0.125+-0.217, PullRequestEvent (5 events): MAR=167.50+-55.01, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=141.69+-69.65, HITS_10=0.083+-0.186\n",
      "Slot 1: FollowEvent (109 events): MAR=104.41+-60.68, HITS_10=0.179+-0.249, ForkEvent (101 events): MAR=135.12+-64.11, HITS_10=0.119+-0.213, PushEvent (75 events): MAR=157.60+-64.28, HITS_10=0.040+-0.136, WatchEvent (930 events): MAR=102.44+-57.12, HITS_10=0.196+-0.248, IssuesEvent (144 events): MAR=172.86+-71.31, HITS_10=0.069+-0.173, IssueCommentEvent (409 events): MAR=163.99+-70.60, HITS_10=0.097+-0.197, PullRequestEvent (123 events): MAR=163.64+-65.50, HITS_10=0.069+-0.173, CommitCommentEvent (19 events): MAR=110.21+-74.46, HITS_10=0.158+-0.283, Com (1801 events): MAR=130.44+-69.95, HITS_10=0.143+-0.229\n",
      "Slot 2: FollowEvent (2 events): MAR=131.75+-51.75, HITS_10=0.000+-0.000, ForkEvent (5 events): MAR=135.20+-65.96, HITS_10=0.000+-0.000, PushEvent (1 events): MAR=118.50+-0.00, HITS_10=0.000+-0.000, WatchEvent (21 events): MAR=93.17+-51.86, HITS_10=0.167+-0.236, IssuesEvent (1 events): MAR=38.50+-0.00, HITS_10=0.500+-0.000, IssueCommentEvent (2 events): MAR=227.25+-12.25, HITS_10=0.000+-0.000, PullRequestEvent (2 events): MAR=72.25+-20.25, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (32 events): MAR=105.89+-62.12, HITS_10=0.125+-0.217\n",
      "Slot 3: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 4: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 5: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 4: results per event type for all test time slots: \n",
      "====== FollowEvent\t (113     events): \tMAR=104.90+-60.10\t HITS_10=0.173+-0.247\n",
      "====== ForkEvent \t (108     events): \tMAR=134.56+-64.75\t HITS_10=0.116+-0.211\n",
      "====== PushEvent \t (91      events): \tMAR=163.76+-63.30\t HITS_10=0.033+-0.124\n",
      "====== WatchEvent\t (977     events): \tMAR=102.70+-57.28\t HITS_10=0.192+-0.247\n",
      "====== IssuesEvent\t (147     events): \tMAR=170.36+-72.69\t HITS_10=0.078+-0.182\n",
      "====== IssueCommentEvent\t (415     events): \tMAR=163.71+-70.65\t HITS_10=0.096+-0.197\n",
      "====== PullRequestEvent\t (130     events): \tMAR=162.38+-65.64\t HITS_10=0.065+-0.169\n",
      "====== CommitCommentEvent\t (19      events): \tMAR=110.21+-74.46\t HITS_10=0.158+-0.283\n",
      "====== Com       \t (1887    events): \tMAR=130.35+-69.92\t HITS_10=0.141+-0.228\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TRAIN epoch=4/5, batch=59/59, sec/iter: 97.7468, loss=0.692, loss components: [15.228012084960938, 123.14759826660156]\n",
      "time 2013-08-31 23:56:55\n",
      "test 0\n",
      "test 10\n",
      "test 20\n",
      "test 30\n",
      "test 40\n",
      "\n",
      "TEST batch=46/46, loss=1038.487, psi=[0.5203856229782104, 0.5171489715576172], loss1 min/max=0.0632/2.0807, loss2 min/max=0.0066/0.4270, integral time stamps=5000, sec/iter=199.3290\n",
      "Slot 0: FollowEvent (2 events): MAR=103.75+-32.75, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=97.25+-75.75, HITS_10=0.250+-0.250, PushEvent (15 events): MAR=218.33+-39.04, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=127.56+-63.64, HITS_10=0.077+-0.180, IssuesEvent (2 events): MAR=26.75+-24.75, HITS_10=0.750+-0.250, IssueCommentEvent (4 events): MAR=143.88+-78.41, HITS_10=0.000+-0.000, PullRequestEvent (5 events): MAR=182.50+-57.88, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=154.21+-75.25, HITS_10=0.074+-0.202\n",
      "Slot 1: FollowEvent (109 events): MAR=106.11+-57.50, HITS_10=0.179+-0.240, ForkEvent (101 events): MAR=140.46+-65.32, HITS_10=0.119+-0.213, PushEvent (75 events): MAR=167.01+-66.20, HITS_10=0.033+-0.125, WatchEvent (930 events): MAR=105.84+-59.35, HITS_10=0.199+-0.251, IssuesEvent (144 events): MAR=182.36+-73.05, HITS_10=0.073+-0.186, IssueCommentEvent (409 events): MAR=171.33+-73.17, HITS_10=0.106+-0.205, PullRequestEvent (123 events): MAR=172.15+-69.00, HITS_10=0.077+-0.181, CommitCommentEvent (19 events): MAR=122.00+-75.56, HITS_10=0.132+-0.220, Com (1801 events): MAR=136.02+-72.98, HITS_10=0.147+-0.232\n",
      "Slot 2: FollowEvent (101 events): MAR=107.22+-58.39, HITS_10=0.124+-0.216, ForkEvent (116 events): MAR=131.70+-59.41, HITS_10=0.125+-0.226, PushEvent (100 events): MAR=188.78+-62.24, HITS_10=0.050+-0.150, WatchEvent (880 events): MAR=96.72+-53.61, HITS_10=0.229+-0.259, IssuesEvent (145 events): MAR=166.70+-68.57, HITS_10=0.079+-0.183, IssueCommentEvent (351 events): MAR=158.11+-73.36, HITS_10=0.115+-0.221, PullRequestEvent (87 events): MAR=158.55+-67.43, HITS_10=0.086+-0.189, CommitCommentEvent (26 events): MAR=163.29+-60.98, HITS_10=0.096+-0.197, Com (1705 events): MAR=127.26+-69.64, HITS_10=0.166+-0.243\n",
      "Slot 3: FollowEvent (152 events): MAR=104.52+-62.83, HITS_10=0.217+-0.291, ForkEvent (94 events): MAR=120.63+-59.12, HITS_10=0.133+-0.221, PushEvent (52 events): MAR=175.65+-67.66, HITS_10=0.067+-0.171, WatchEvent (887 events): MAR=100.78+-56.06, HITS_10=0.250+-0.262, IssuesEvent (102 events): MAR=149.59+-71.95, HITS_10=0.127+-0.229, IssueCommentEvent (362 events): MAR=149.13+-68.80, HITS_10=0.127+-0.221, PullRequestEvent (86 events): MAR=139.58+-63.07, HITS_10=0.093+-0.195, CommitCommentEvent (35 events): MAR=156.43+-86.13, HITS_10=0.114+-0.210, Com (1618 events): MAR=121.50+-66.52, HITS_10=0.191+-0.251\n",
      "Slot 4: FollowEvent (51 events): MAR=99.64+-59.16, HITS_10=0.186+-0.242, ForkEvent (93 events): MAR=116.56+-63.24, HITS_10=0.129+-0.231, PushEvent (92 events): MAR=191.07+-65.23, HITS_10=0.060+-0.162, WatchEvent (817 events): MAR=97.44+-53.23, HITS_10=0.222+-0.256, IssuesEvent (154 events): MAR=179.23+-72.53, HITS_10=0.075+-0.178, IssueCommentEvent (521 events): MAR=174.83+-73.08, HITS_10=0.104+-0.203, PullRequestEvent (149 events): MAR=187.16+-64.81, HITS_10=0.047+-0.157, CommitCommentEvent (25 events): MAR=155.46+-66.58, HITS_10=0.080+-0.183, Com (1851 events): MAR=139.65+-74.90, HITS_10=0.148+-0.233\n",
      "Slot 5: FollowEvent (no events), ForkEvent (57 events): MAR=118.12+-50.18, HITS_10=0.184+-0.241, PushEvent (65 events): MAR=205.78+-61.13, HITS_10=0.054+-0.155, WatchEvent (829 events): MAR=98.77+-53.30, HITS_10=0.257+-0.257, IssuesEvent (120 events): MAR=187.45+-70.88, HITS_10=0.087+-0.190, IssueCommentEvent (439 events): MAR=167.90+-72.81, HITS_10=0.106+-0.210, PullRequestEvent (120 events): MAR=175.71+-70.08, HITS_10=0.046+-0.144, CommitCommentEvent (25 events): MAR=165.68+-75.70, HITS_10=0.060+-0.215, Com (1655 events): MAR=135.00+-73.18, HITS_10=0.176+-0.244\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 4: results per event type for all test time slots: \n",
      "====== FollowEvent\t (415     events): \tMAR=104.99+-59.87\t HITS_10=0.180+-0.257\n",
      "====== ForkEvent \t (463     events): \tMAR=126.50+-61.25\t HITS_10=0.134+-0.226\n",
      "====== PushEvent \t (399     events): \tMAR=187.39+-65.03\t HITS_10=0.050+-0.150\n",
      "====== WatchEvent\t (4369    events): \tMAR=100.20+-55.46\t HITS_10=0.230+-0.258\n",
      "====== IssuesEvent\t (667     events): \tMAR=173.67+-72.85\t HITS_10=0.088+-0.196\n",
      "====== IssueCommentEvent\t (2086    events): \tMAR=165.35+-72.97\t HITS_10=0.110+-0.211\n",
      "====== PullRequestEvent\t (570     events): \tMAR=169.92+-68.77\t HITS_10=0.066+-0.172\n",
      "====== CommitCommentEvent\t (130     events): \tMAR=154.36+-75.66\t HITS_10=0.096+-0.207\n",
      "====== Com       \t (8684    events): \tMAR=132.29+-71.96\t HITS_10=0.164+-0.241\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Adj_all (284, 284) 1 0.0 15.0\n",
      "initialize models node embeddings and adjacency matrices for 284 nodes\n",
      "A_initial (284, 284)\n",
      "Warning: time_keys is empty. No operations performed.\n",
      "\n",
      "TRAIN epoch=5/5, batch=20/59, sec/iter: 40.8642, loss=5.134, loss components: [98.57275390625, 928.2069091796875]\n",
      "time 2013-04-10 14:13:33\n",
      "test 0\n",
      "\n",
      "TEST batch=10/46, loss=1063.904, psi=[0.5211504101753235, 0.5170659422874451], loss1 min/max=0.0384/2.1748, loss2 min/max=0.0005/0.6007, integral time stamps=5000, sec/iter=36.8375\n",
      "Slot 0: FollowEvent (2 events): MAR=126.25+-37.25, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=103.50+-73.00, HITS_10=0.000+-0.000, PushEvent (15 events): MAR=187.73+-33.64, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=133.23+-55.22, HITS_10=0.096+-0.197, IssuesEvent (2 events): MAR=53.25+-9.25, HITS_10=0.500+-0.000, IssueCommentEvent (4 events): MAR=85.75+-53.71, HITS_10=0.000+-0.000, PullRequestEvent (5 events): MAR=156.50+-44.55, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=142.94+-59.98, HITS_10=0.065+-0.168\n",
      "Slot 1: FollowEvent (109 events): MAR=98.20+-56.92, HITS_10=0.179+-0.240, ForkEvent (101 events): MAR=134.20+-58.61, HITS_10=0.114+-0.210, PushEvent (75 events): MAR=149.95+-59.13, HITS_10=0.033+-0.125, WatchEvent (930 events): MAR=99.52+-53.83, HITS_10=0.193+-0.246, IssuesEvent (144 events): MAR=161.43+-65.80, HITS_10=0.069+-0.173, IssueCommentEvent (409 events): MAR=153.37+-65.92, HITS_10=0.097+-0.197, PullRequestEvent (123 events): MAR=151.35+-62.11, HITS_10=0.065+-0.168, CommitCommentEvent (19 events): MAR=110.87+-69.22, HITS_10=0.132+-0.220, Com (1801 events): MAR=124.40+-64.70, HITS_10=0.141+-0.226\n",
      "Slot 2: FollowEvent (2 events): MAR=120.50+-49.00, HITS_10=0.000+-0.000, ForkEvent (5 events): MAR=127.50+-64.91, HITS_10=0.000+-0.000, PushEvent (1 events): MAR=114.00+-0.00, HITS_10=0.000+-0.000, WatchEvent (21 events): MAR=90.33+-51.90, HITS_10=0.167+-0.236, IssuesEvent (1 events): MAR=39.00+-0.00, HITS_10=0.500+-0.000, IssueCommentEvent (2 events): MAR=221.75+-10.75, HITS_10=0.000+-0.000, PullRequestEvent (2 events): MAR=68.25+-20.75, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (32 events): MAR=102.11+-61.21, HITS_10=0.125+-0.217\n",
      "Slot 3: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 4: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 5: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 5: results per event type for all test time slots: \n",
      "====== FollowEvent\t (113     events): \tMAR=99.09+-56.69\t HITS_10=0.173+-0.238\n",
      "====== ForkEvent \t (108     events): \tMAR=133.32+-59.37\t HITS_10=0.106+-0.205\n",
      "====== PushEvent \t (91      events): \tMAR=155.78+-57.30\t HITS_10=0.027+-0.114\n",
      "====== WatchEvent\t (977     events): \tMAR=100.22+-54.12\t HITS_10=0.190+-0.245\n",
      "====== IssuesEvent\t (147     events): \tMAR=159.13+-67.07\t HITS_10=0.078+-0.182\n",
      "====== IssueCommentEvent\t (415     events): \tMAR=153.04+-66.16\t HITS_10=0.095+-0.196\n",
      "====== PullRequestEvent\t (130     events): \tMAR=150.27+-61.96\t HITS_10=0.062+-0.164\n",
      "====== CommitCommentEvent\t (19      events): \tMAR=110.87+-69.22\t HITS_10=0.132+-0.220\n",
      "====== Com       \t (1887    events): \tMAR=124.56+-64.65\t HITS_10=0.138+-0.225\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TRAIN epoch=5/5, batch=40/59, sec/iter: 47.9248, loss=5.652, loss components: [102.31529235839844, 1028.1795654296875]\n",
      "time 2013-06-30 03:40:38\n",
      "test 0\n",
      "\n",
      "TEST batch=10/46, loss=1130.200, psi=[0.5215226411819458, 0.5167961120605469], loss1 min/max=0.0731/2.2999, loss2 min/max=0.0048/0.4709, integral time stamps=5000, sec/iter=38.2019\n",
      "Slot 0: FollowEvent (2 events): MAR=100.25+-8.25, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=108.75+-89.75, HITS_10=0.250+-0.250, PushEvent (15 events): MAR=195.07+-47.12, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=119.90+-62.85, HITS_10=0.096+-0.197, IssuesEvent (2 events): MAR=57.25+-6.25, HITS_10=0.500+-0.000, IssueCommentEvent (4 events): MAR=102.38+-49.70, HITS_10=0.125+-0.217, PullRequestEvent (5 events): MAR=165.10+-54.07, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=140.94+-69.00, HITS_10=0.083+-0.186\n",
      "Slot 1: FollowEvent (109 events): MAR=103.56+-60.14, HITS_10=0.183+-0.250, ForkEvent (101 events): MAR=134.40+-62.85, HITS_10=0.119+-0.213, PushEvent (75 events): MAR=156.39+-64.25, HITS_10=0.033+-0.125, WatchEvent (930 events): MAR=101.63+-56.34, HITS_10=0.198+-0.248, IssuesEvent (144 events): MAR=171.23+-71.04, HITS_10=0.069+-0.173, IssueCommentEvent (409 events): MAR=162.61+-70.24, HITS_10=0.109+-0.206, PullRequestEvent (123 events): MAR=161.44+-65.05, HITS_10=0.073+-0.177, CommitCommentEvent (19 events): MAR=109.63+-75.07, HITS_10=0.132+-0.220, Com (1801 events): MAR=129.33+-69.28, HITS_10=0.147+-0.230\n",
      "Slot 2: FollowEvent (2 events): MAR=130.75+-51.25, HITS_10=0.000+-0.000, ForkEvent (5 events): MAR=133.00+-66.64, HITS_10=0.000+-0.000, PushEvent (1 events): MAR=116.00+-0.00, HITS_10=0.000+-0.000, WatchEvent (21 events): MAR=91.88+-50.84, HITS_10=0.167+-0.236, IssuesEvent (1 events): MAR=41.00+-0.00, HITS_10=0.500+-0.000, IssueCommentEvent (2 events): MAR=227.50+-11.50, HITS_10=0.000+-0.000, PullRequestEvent (2 events): MAR=70.25+-23.25, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (32 events): MAR=104.59+-61.75, HITS_10=0.125+-0.217\n",
      "Slot 3: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 4: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "Slot 5: FollowEvent (no events), ForkEvent (no events), PushEvent (no events), WatchEvent (no events), IssuesEvent (no events), IssueCommentEvent (no events), PullRequestEvent (no events), CommitCommentEvent (no events), Com (no events)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 5: results per event type for all test time slots: \n",
      "====== FollowEvent\t (113     events): \tMAR=103.98+-59.58\t HITS_10=0.177+-0.248\n",
      "====== ForkEvent \t (108     events): \tMAR=133.86+-63.72\t HITS_10=0.116+-0.211\n",
      "====== PushEvent \t (91      events): \tMAR=162.32+-63.23\t HITS_10=0.027+-0.114\n",
      "====== WatchEvent\t (977     events): \tMAR=101.91+-56.51\t HITS_10=0.195+-0.247\n",
      "====== IssuesEvent\t (147     events): \tMAR=168.80+-72.32\t HITS_10=0.078+-0.182\n",
      "====== IssueCommentEvent\t (415     events): \tMAR=162.34+-70.30\t HITS_10=0.108+-0.206\n",
      "====== PullRequestEvent\t (130     events): \tMAR=160.18+-65.20\t HITS_10=0.069+-0.173\n",
      "====== CommitCommentEvent\t (19      events): \tMAR=109.63+-75.07\t HITS_10=0.132+-0.220\n",
      "====== Com       \t (1887    events): \tMAR=129.24+-69.25\t HITS_10=0.145+-0.229\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TRAIN epoch=5/5, batch=59/59, sec/iter: 50.1461, loss=0.785, loss components: [13.450953483581543, 143.5062255859375]\n",
      "time 2013-08-31 23:56:55\n",
      "test 0\n",
      "test 10\n",
      "test 20\n",
      "test 30\n",
      "test 40\n",
      "\n",
      "TEST batch=46/46, loss=1171.810, psi=[0.5217629075050354, 0.516517698764801], loss1 min/max=0.0677/2.4172, loss2 min/max=0.0066/0.4890, integral time stamps=5000, sec/iter=33.2730\n",
      "Slot 0: FollowEvent (2 events): MAR=103.00+-33.00, HITS_10=0.000+-0.000, ForkEvent (2 events): MAR=97.00+-76.50, HITS_10=0.250+-0.250, PushEvent (15 events): MAR=216.27+-41.68, HITS_10=0.000+-0.000, WatchEvent (26 events): MAR=126.13+-63.74, HITS_10=0.077+-0.180, IssuesEvent (2 events): MAR=26.50+-24.50, HITS_10=0.750+-0.250, IssueCommentEvent (4 events): MAR=143.38+-77.80, HITS_10=0.000+-0.000, PullRequestEvent (5 events): MAR=179.70+-59.02, HITS_10=0.000+-0.000, CommitCommentEvent (no events), Com (54 events): MAR=152.64+-75.43, HITS_10=0.074+-0.202\n",
      "Slot 1: FollowEvent (109 events): MAR=105.72+-56.98, HITS_10=0.174+-0.238, ForkEvent (101 events): MAR=139.79+-64.45, HITS_10=0.119+-0.213, PushEvent (75 events): MAR=165.97+-66.29, HITS_10=0.033+-0.125, WatchEvent (930 events): MAR=105.33+-58.64, HITS_10=0.201+-0.251, IssuesEvent (144 events): MAR=181.26+-72.86, HITS_10=0.073+-0.186, IssueCommentEvent (409 events): MAR=170.44+-72.95, HITS_10=0.112+-0.209, PullRequestEvent (123 events): MAR=170.96+-68.48, HITS_10=0.077+-0.181, CommitCommentEvent (19 events): MAR=122.34+-76.11, HITS_10=0.132+-0.220, Com (1801 events): MAR=135.31+-72.44, HITS_10=0.150+-0.233\n",
      "Slot 2: FollowEvent (101 events): MAR=106.97+-58.11, HITS_10=0.124+-0.216, ForkEvent (116 events): MAR=130.26+-58.80, HITS_10=0.125+-0.226, PushEvent (100 events): MAR=187.49+-62.25, HITS_10=0.050+-0.150, WatchEvent (880 events): MAR=96.14+-53.21, HITS_10=0.232+-0.262, IssuesEvent (145 events): MAR=164.95+-69.04, HITS_10=0.090+-0.192, IssueCommentEvent (351 events): MAR=156.81+-73.23, HITS_10=0.120+-0.223, PullRequestEvent (87 events): MAR=156.53+-67.24, HITS_10=0.098+-0.198, CommitCommentEvent (26 events): MAR=161.56+-61.79, HITS_10=0.096+-0.197, Com (1705 events): MAR=126.24+-69.26, HITS_10=0.170+-0.246\n",
      "Slot 3: FollowEvent (152 events): MAR=104.07+-62.20, HITS_10=0.211+-0.284, ForkEvent (94 events): MAR=118.76+-58.01, HITS_10=0.138+-0.224, PushEvent (52 events): MAR=173.84+-67.47, HITS_10=0.077+-0.180, WatchEvent (887 events): MAR=100.30+-55.73, HITS_10=0.253+-0.264, IssuesEvent (102 events): MAR=148.44+-71.88, HITS_10=0.127+-0.229, IssueCommentEvent (362 events): MAR=147.55+-68.43, HITS_10=0.134+-0.225, PullRequestEvent (86 events): MAR=138.30+-63.04, HITS_10=0.093+-0.195, CommitCommentEvent (35 events): MAR=154.94+-85.38, HITS_10=0.114+-0.210, Com (1618 events): MAR=120.54+-66.01, HITS_10=0.195+-0.253\n",
      "Slot 4: FollowEvent (51 events): MAR=99.56+-58.92, HITS_10=0.186+-0.242, ForkEvent (93 events): MAR=115.48+-62.52, HITS_10=0.140+-0.236, PushEvent (92 events): MAR=188.51+-65.11, HITS_10=0.060+-0.162, WatchEvent (817 events): MAR=96.74+-52.84, HITS_10=0.228+-0.256, IssuesEvent (154 events): MAR=177.05+-71.57, HITS_10=0.075+-0.178, IssueCommentEvent (521 events): MAR=172.73+-73.01, HITS_10=0.109+-0.207, PullRequestEvent (149 events): MAR=185.15+-64.90, HITS_10=0.050+-0.161, CommitCommentEvent (25 events): MAR=153.64+-66.98, HITS_10=0.080+-0.183, Com (1851 events): MAR=138.20+-74.28, HITS_10=0.153+-0.235\n",
      "Slot 5: FollowEvent (no events), ForkEvent (57 events): MAR=117.12+-49.59, HITS_10=0.184+-0.241, PushEvent (65 events): MAR=203.86+-61.11, HITS_10=0.054+-0.155, WatchEvent (829 events): MAR=98.19+-52.86, HITS_10=0.257+-0.253, IssuesEvent (120 events): MAR=185.41+-71.26, HITS_10=0.096+-0.207, IssueCommentEvent (439 events): MAR=165.97+-72.26, HITS_10=0.112+-0.214, PullRequestEvent (120 events): MAR=173.73+-70.51, HITS_10=0.054+-0.155, CommitCommentEvent (25 events): MAR=163.74+-75.22, HITS_10=0.060+-0.215, Com (1655 events): MAR=133.76+-72.56, HITS_10=0.179+-0.244\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 5: results per event type for all test time slots: \n",
      "====== FollowEvent\t (415     events): \tMAR=104.65+-59.40\t HITS_10=0.176+-0.253\n",
      "====== ForkEvent \t (463     events): \tMAR=125.27+-60.50\t HITS_10=0.137+-0.228\n",
      "====== PushEvent \t (399     events): \tMAR=185.65+-65.00\t HITS_10=0.051+-0.152\n",
      "====== WatchEvent\t (4369    events): \tMAR=99.62+-55.00\t HITS_10=0.233+-0.258\n",
      "====== IssuesEvent\t (667     events): \tMAR=172.01+-72.71\t HITS_10=0.091+-0.201\n",
      "====== IssueCommentEvent\t (2086    events): \tMAR=163.75+-72.69\t HITS_10=0.116+-0.215\n",
      "====== PullRequestEvent\t (570     events): \tMAR=168.20+-68.70\t HITS_10=0.070+-0.176\n",
      "====== CommitCommentEvent\t (130     events): \tMAR=152.94+-75.49\t HITS_10=0.096+-0.207\n",
      "====== Com       \t (8684    events): \tMAR=131.21+-71.42\t HITS_10=0.168+-0.242\n",
      "----------------------------------------------------------------------------------------------------\n",
      "end time: 2024-06-14 09:07:37.272114\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "for epoch in range(epoch_start, epochs + 1):\n",
    "    # Setting the global time_bar for the datasets\n",
    "    if not (epoch == epoch_start):\n",
    "        # Reinitialize node embeddings and adjacency matrices, but keep the model parameters intact\n",
    "        time_bar, node_degree_global = initalize_state(train_loader.dataset, keepS=epoch > 1)\n",
    "        model.node_degree_global = node_degree_global\n",
    "        \n",
    "    # Setting the global time_bar for the datasets\n",
    "    train_loader.dataset.time_bar = time_bar\n",
    "    test_loader.dataset.time_bar = time_bar\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for batch_idx, data_batch in enumerate(train_loader):\n",
    "        # if batch_idx <= batch_start:\n",
    "        #   continue\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Ensure the data is in the correct format\n",
    "        data_batch[2] = data_batch[2].float()\n",
    "        data_batch[4] = data_batch[4].double()\n",
    "        data_batch[5] = data_batch[5].double()\n",
    "\n",
    "        output = model(data_batch)\n",
    "        losses = [-torch.sum(torch.log(output[0]) + 1e-10), weight * torch.sum(output[1])]\n",
    "\n",
    "        # KL losses (if there are additional items in output to process as losses)\n",
    "        if len(output) > 3 and output[-1] is not None:\n",
    "            losses.extend(output[-1])\n",
    "\n",
    "        loss = torch.sum(torch.stack(losses)) / batch_size\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_value_(model.parameters(), 100)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses_events.append(losses[0].item())\n",
    "        losses_nonevents.append(losses[1].item())\n",
    "        losses_sum.append(loss.item())\n",
    "\n",
    "        # Clamping psi to prevent numerical overflow\n",
    "        model.psi.data = torch.clamp(model.psi.data, 1e-1, 1e+3)\n",
    "\n",
    "        time_iter = time.time() - start\n",
    "\n",
    "        # Detach computational graph to prevent unwanted backprop\n",
    "        model.z = model.z.detach()\n",
    "        model.S = model.S.detach()\n",
    "\n",
    "        if (batch_idx + 1) % log_interval == 0 or batch_idx == len(train_loader) - 1:\n",
    "            print(f'\\nTRAIN epoch={epoch}/{epochs}, batch={batch_idx + 1}/{len(train_loader)}, '\n",
    "                  f'sec/iter: {time_iter / (batch_idx + 1):.4f}, loss={loss.item():.3f}, '\n",
    "                  f'loss components: {[l.item() for l in losses]}')\n",
    "\n",
    "            # Save state before testing\n",
    "            variables = get_temporal_variables()\n",
    "            print('time', datetime.datetime.fromtimestamp(np.max(time_bar)))\n",
    "\n",
    "            # Testing and collecting results\n",
    "            result = test(model, n_test_batches=None if batch_idx == len(train_loader) - 1 else 10, epoch=epoch)\n",
    "            test_MAR.append(np.mean(result[0]['Com']))\n",
    "            test_HITS10.append(np.mean(result[1]['Com']))\n",
    "            test_loss.append(result[2])\n",
    "\n",
    "            # Restore state after testing\n",
    "            time_bar = set_temporal_variables(variables, model, train_loader, test_loader)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print('end time:', datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
